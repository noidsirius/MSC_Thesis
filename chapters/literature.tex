
\فصل{کارهای پیشین}

در این فصل کارهای پیشین انجام‌شده روی مسئله‌ی $k$-مرکز، در سه بخش مورد بررسی قرار می‌گیرد.
در بخش اول، مسائل قطر، عرض و $k$-مرکز در مدل ایستا مورد بررسی قرار می‌گیرد.
در بخش دوم، مسائل قطر و عرض در حالت پنجره‌ی لغزان و مجموعه هسته‌های مطرح برای این مسئله مورد بررسی قرار می‌گیرد و در نهایت، در بخش سوم، مسئله‌ی $k$-مرکز در مدل پنجره‌ی لغزان مورد بررسی قرار می‌گیرد.

\قسمت{مسائل بهینه‌سازی هندسی در مدل ایستا}

در این بخش می‌خواهیم مسائلی از بهینه‌سازی هندسی را در مدل ایستا بررسی کنیم که یا در هدف این پژوهش بوده‌اند (قطر و  $k$-مرکز) یا پژوهش مهمی در مدل پنجره‌ی لغزان آن شده است (عرض نقاط).

\زیرقسمت{قطر}
مسئله‌ی قطر در مدل ایستا معادل پیداکردن دورترین فاصله بین هر دو نقطه‌ای از $n$ نقطه‌ی ورودی است. ابتدایی‌ترین روش برای این مسئله مقایسه‌ی تمامی 
$ {{n}\choose{2}} $
مقدار ممکن است. برای فضای اقلیدسی $d$-بعدی کران پایین $\omega(n log n)$ ثابت شده است. \مرجع{preparata1985introduction} در فضای ۲-بعدی با استفاده از ایده‌ی پوش محدب می‌توان قطر را در مرتبه‌ی زمانی $O(n log n)$ به دست آورد. واضح است که نقاطی که قطر را تشکیل می‌دهند باید جزو رئوس پوش محدب باشند، پس با مرتبه‌ی زمانی $O(n log n)$ ابتدا پوش محدب را به دست می‌آوریم، سپس به ازای هر راس پوش محدب به وسیله‌ی جستجوی دودویی \پاورقی{ Binary Search} دورترین راس پوش را نسبت به آن راس به دست می‌آوریم. هم‌چنین محاسبه‌ی قطر در فضای ۲-بعدی کران پایین $\omega(n)$ را دارد. در فضای ۳-بعدی کار اندکی سخت‌تر است ولی الگوریتم با مرتبه‌ی زمانی $O( n log n)$ وجود دارد \مرجع{ramos2000deterministic}.

همان‌طور که دیده می‌شود روش‌های مسئله‌ی محاسبه‌ی قطر در ابعاد پایین مرتبه‌ی زمانی نزدیک به خطی دارند اما به علت این که برای ابعاد بالا روش کارآمدی وجود ندارد و حتی همین الگوریتم‌های ابعاد پایین با مرتبه‌ی خطی و زیرخطی فاصله دارند پژوهش‌هایی در راستای ارائه‌ی الگوریتم تقریبی برای قطر نقاط صورت گرفته است. یک الگوریتم تقریبی نسبتا بدیهی ۲-تقریب با مرتبه‌ی زمانی $O(dn)$ وجود دارد که یک نقطه را می‌گیرد و دورترین نقطه نسبت به آن را پیدا می‌کند، قطر از ۲ برابر این مقدار قطعا کوچک‌تر است پس ۲ برابر این مقدار یک ۲-تقریب برای قطر به شمار می‌آید. در ادامه یک الگوریتم $\sqrt{3}$-تقریب برای محاسبه‌ی قطر در $d$-بعد ارائه شده است \مرجع{eg̃eciog̃lu1989approximating}. تلاش‌هایی برای ارائه‌ی الگوریتم $(1 + O(\epsilon))$-تقریب هم صورت گرفته است که به علت مرتبه‌ی زمانی نسبتا بالا دیگر به آن نمی‌پردازیم.

\زیرقسمت{عرض}
ابتدا مفهوم عرض نقاط در فضا $d$-بعدی را به صورت غیررسمی بیان می‌کنیم.
\شروع{تعریف}
\مهم{عرض نقاط:} مجموعه‌ی $P$ شامل تعدادی نقاط $d$-بعدی است. دو صفحه\پاورقی{Hyperplane} موازی را به نام‌های $HP_1$ و $HP_2$ در نظر بگیرید که تمامی نقاط $P$ بین این دو صفحه قرار دارد. به کم‌ترین فاصله‌ی بین هر دو صفحه عرض نقاط می‌گوییم و با $w(P)$ نمایش می‌دهیم.
\پایان{تعریف}
  همان‌طور که در قسمت قطر گفته شد می‌توان در فضای ۲-بعدی عرض نقاط را به صورت دقیق در زمان $O(n log n)$ به دست آورد \مرجع{preparata1985introduction}. محاسبه‌ی عرض نقاط در ابعاد بالاتر به سادگی محاسبه‌ی قطر نیست. در فضای ۳-بعدی اولین الگوریتمی که برای حل دقیق ارائه شد مرتبه‌ی زمانی $O(n^2)$ داشت \مرجع{houle1988computing}. ایده‌ی این الگوریتم از تکنیک چرخاندن کولیس \پاورقی{‌Rotating Calipers} به دست می‌آید. علت نام‌گذاری این روش شباهت آن به اندازه‌گیری یک جسم چندوجهی به وسیله‌ی کولیس است که وقتی یک بازوی کولیس با یک یال چندوجهی تماس پیدا می‌کند بازوی دیگر به یک نقطه‌ی چندوجهی می‌رسد که این دو نقطه، جفت پادپایی \پاورقی{Antipodal Pair} هستند. به وسیله‌ی چرخاندن چندوجهی می‌توان تمام جفت‌های پادپایی را شناسایی کرد که فاصله‌ی کوچک‌ترین آن‌ها برابر با عرض خواهد بود \مرجع{preparata1985introduction}. برای ابعاد بالاتر روشی با مرتبه‌ی زمانی
   $O(n^{\lfloor \frac{d}{2} \rfloor})$
وجود دارد \مرجع{clarkson1989applications}.

یکی از مهم‌ترین پیش‌رفت‌ها در الگوریتم‌های تقریبی هندسی در حوزه‌ی محاسبه‌ی عرض نقاط به وجود آمده است. معرفی ایده‌ی $\epsilon$-هسته علاوه بر این که بستری برای کاهش حجم نقاط ورودی با کاهش دقت در تقریب $(1+ \epsilon)$ ایجاد کرد، ابزار بسیار قدرتمندی برای حل مسائل بهینه‌سازی هندسی در مدل‌های جویبار داده به شمار آمد. قبل از $\epsilon$-هسته روش‌هایی برای محاسبه‌ی عرض نقاط با تقریب  $(1+ \epsilon)$  ارائه شده بود \مرجع{duncan1999efficient} اما مرتبه‌ی زمانی بالایی مصرف می‌کرد و پیچیده بود که در پژوهش‌های دیگری سعی کردند این موارد را بهبود دادند \مرجع{chan2000approximating}. 
\زیرقسمت{$k$-مرکز}
همان‌طور که در فصل‌های قبل گفتیم مسئله‌ی $k$-مرکز مسئله‌ای معروف در علوم کامپیوتر است. می‌خواهیم مراکزی را انتخاب کنیم که بیش‌ترین فاصله‌ی نقاط از مرکز دسته‌ی متناظرش کمینه شود. در صورتی که مراکز مشخص باشند محاسبه‌ی این مقدار (شعاع) بسیار ساده است.

این مسئله در حالت کلی $NP$-سخت است \مرجع{michael1979computers}. شاید این طور تصور شود که در فضای اقلیدسی یا ابعاد پایین مسئله ساده‌تر می‌شود اما ثابت شده است که این مسئله در صفحه‌ی دوبعدی نیز $NP$-سخت است \مرجع{megiddo1984complexity}. علاوه بر این که راه حل چندجمله‌ای برای حل دقیق این مسئله وجود ندارد ثابت شده است که هیچ الگوریتم تقریبی با ضریب تقریب بهتر از $2$ نیز برای تقریب‌زدن این مسئله وجود ندارد.

یکی از اولین الگوریتم‌های تقریبی که این کران پایین را پوشش می‌دهد توسط گنزالز ارائه شده است \مرجع{gonzalez1985clustering}. این الگوریتم یک الگوریتم تقریبی با ضریب تقریب ۲ است و زمان مصرفی آن $\cO(kn)$ است. ابتدا تابع فاصله‌ی یک نقطه از یک مجموعه را تعریف می‌کنیم.

\شروع{تعریف}
فاصله‌ی نقطه‌ی $v$ از مجموعه‌ای ناتهی از نقاط $S$ را برابر فاصله‌ی نقطه‌ای درون $S$ از $v$ تعریف می‌کنیم، به‌گونه‌ای که از تمام نقاط $S$ به $v$ نزدیک‌تر باشد. در واقع داریم:
$$d(v, S) = \min_{u \in S} \set{ d(u, v) }$$
\پایان{تعریف}

در الگوریتم گنزالز، یک مجموعه داریم که مراکز پیشنهادی را به تدریج به آن اضافه می‌کنیم. ابتدا یک نقطه‌ی دلخواه را به عنوان اولین مرکز به این مجموعه اضافه کنیم. سپس در هر مرحله نقطه‌ای که بیش‌ترین فاصله را با این مجموعه‌ی مراکز دارد به عنوان مرکز بعدی به مجموعه اضافه می‌کنیم. این کار را تا وقتی تکرار می‌کنیم که مجموعه‌ی مذکور دارای $k$ عضو شده باشد. حال هر نقطه را به مرکزی اختصاص می‌دهیم که کم‌ترین فاصله را با آن دارد. ثابت می‌شود که بیش‌ترین فاصله‌ی مراکز با نقاط دسته‌ی متناظرشان حداکثر دو برابر شعاع بهینه در مسئله‌ی $k$-مرکز است. به عبارت دیگر این الگوریتم ضریب تقریب $2$ دارد.

نمونه‌ای از اجرای الگوریتم گنزالز برای مسئله‌ی $4$-مرکز در شکل \رجوع{شکل:گنزالز} نشان داده شده است.

\شروع{شکل}
\centerimg{gonzalez}{10cm}
\شرح[نمونه‌ی الگوریتم گنزالز]{نقاطی که مربع دارند مراکز پیشنهادی  $4$-مرکز الگوریتم گنزالز هستند. نقطه‌ی ۱ ابتدا به صورت تصادفی انتخاب می‌شود. سپس نقطه‌ی ۲ بیش‌ترین فاصله را تا مجموعه‌ی شامل نقطه‌ی ۱ دارد پس به عنوان مرکز دوم انتخاب می‌شود. این فرآیند برای نقاط ۳ و ۴ هم تکرار می‌شود.}
\برچسب{شکل:گنزالز}
\پایان{شکل}

مواردی که تا این‌جا مورد بررسی قرار دادیم روی حالات کلی مسئله‌ی $k$-مرکز تمرکز شده بود. با توجه به گستردگی کاربرد مسئله‌ی $k$-مرکز برای حالاتی که $k$ یا $d$ مقدار مشخص و کوچکی دارند پژوهش‌هایی انجام شده است.
به عنوان مثال می‌توان به مسئله‌ی $1$-مرکز هندسی یا کوچک‌ترین کره‌ی محیطی اشاره کرد که برای حل آن الگوریتم با زمان اجرای  $\cO((d+1)! n)$ وجود دارد \مرجع{chazelle1996linear}. این روش یک الگوریتم تصادفی به حساب می‌آید و ایده‌ی اصلی آن این است که چنین کره‌ای را می‌توان با استفاده از حداکثر $d+1$ نقطه شناسایی کرد. علت زمان پایین اجرای این الگوریتم این است که احتمال این که هر نقطه جزو نقاط مرزی باشد پایین است.

هم‌چنین برای مسئله‌ی $2$-مرکز هندسی بهترین الگوریتم نزدیک به خطی با زمان اجرای $\cO(n \log^2{n} \log^2{\log{n}})$ و حافظه‌ی $\cO(n)$ موجود است \مرجع{chan1999more}.


\قسمت{تاریخچه‌ی مدل پنجره‌ی لغزان}
می‌توان گفت مدل پنجره‌ی لغزان در علوم محاسباتی در دو مسیر متفاوت پیشرفت کرد. مسیر اول رویکرد آماری به مسائل بود که خود مدل پنجره‌ی لغزان را معرفی کرد و مسیر دوم مسائل بهینه‌سازی هندسی بودند که از آمار فاصله گرفتند. به علت اهمیت مسئله‌ی $k$-مرکز در مدر پنجره‌ی لغزان، این مسئله را در یک قسمت جدا بررسی خواهیم کرد.
\زیرقسمت{مسائل آماری در پنجره‌ی لغزان}
مدل پنجره‌ی لغزان سال ۲۰۰۲ در \مرجع{datar2002maintaining}
توسط داتار و سایرین ارائه شد. آن‌ها با ارائه‌ی بستر هیستوگرام نمایی \پاورقی{Exponential Histogram} ابتدا مسئله‌ی شمارش ساده را حل کردند سپس با تعمیم آن به مسئله‌ی جمع (مجموع $N$ داده‌ی اخیر) خانواده‌ی توابعی را معرفی کردند که به وسیله‌ی بستر هیستوگرام نمایی می‌توان با تقریب $O(1+\eps)$ و سربار حافظه‌ی $O(\frac{1}{\eps} log N)$ آن‌‌ها را محاسبه کرد. این مقاله علاوه بر این که مدل پنجره‌ی لغزان را معرفی کرد، بستر بسیار مناسبی برای مدل‌سازی مسائل دیگر ارائه داد. مسائل ساده‌ی آماری مانند میانگین در این مقاله به طور کامل پوشش داده شد، بابکوک و سایرین در \مرجع{Babcock:2003:MVK:773153.773176} این روند را ادامه دادند و مسائل واریانس و $K$-میانه \پاورقی{$K-Means$} را حل کردند. فضای حافظه‌ی الگوریتم آن‌ها برای مسئله‌ی $K$-میانه برابر
$O(\frac{k}{\tau^4}N^{2\tau} log^2 N)$
به ازای $ \tau < \frac{1}{2}$  و تقریب
$O(2^{O(\frac{1}{\tau})})$
بود. در این مقاله‌ مسئله‌ی بازی مطرح شد که «آیا الگوریتمی برای مسئله‌ی $K$-میانه وجود دارد که مرتبه‌ی حافظه‌ی آن نسبت به اندازه‌ی پنجره لگاریتمی باشد؟». این مسئله در دو مرحله توسط بریورمن و سایرین حل شد. ابتدا آن‌ها در \مرجع{braverman2010effective}
  هیستوگرام نمایی را هم از نظر دقت تقریب و هم از نظر عمومیت خانواده‌ی توابعی که پشتیبانی می‌کند پیشرفت دادند و نام هیستوگرام ملایم \پاورقی{\lr{Smooth Histogram}} روی آن نهادند. سپس با استفاده از این بستر جدید در  \مرجع{braverman2016clustering}
توانستند مسئله‌ی باز مطرح‌شده $K$-میانه در \مرجع{Babcock:2003:MVK:773153.773176}
را با حافظه‌ی $ O(k^3 log^6 N)$ حل کنند.
حال مسئله‌ی مهمی از این حوزه که پایه‌ی روش‌های دیگر به حساب می‌آید را به طور دقیق‌تر بررسی می‌کنیم.
\زیرزیرقسمت{شمارش ساده}
مدل پنجره‌ی لغزان با معرفی این مسئله شروع شد که منجر به معرفی خانواده‌ای از توابع شد که به وسیله‌ی بستر‌ آن‌ها قابل محاسبه در مدل پنجره‌ی لغزان بود. خانواده‌ی توابع $f$ و مجموعه‌های $A$ و $B$ از داده‌ها را در نظر بگیرید که

\شروع{فقرات}
\item $f(A) \ge 0$
\item $f(A) \le poly(|A|)$
\item $f(A \cup B) \ge f(A) + f(B)$
\item $f(A \cup B) \le C_f (f(A) + f(B))$
\پایان{فقرات}
در عبارات بالا در نظر بگیرید که $C_f$ یک عدد ثابت است که تنها به تابع $f$ وابسته است.

در مسئله‌ی شمارش ساده، داده‌ها اعداد ۰ یا ۱ هستند و می‌خواهیم تعداد داده‌ی ۱ در پنجره‌ی $N$تایی اخیر را بشماریم. برای این مسئله، تابع $f$ را این گونه تعریف می‌کنیم که $f(A) $ برابر است با شماره‌ی نزدیک‌ترین داده‌ی ۱ در مجموعه‌ی $A$. به عنوان مثال اگر $A$ را داده‌های پنجره‌ی $N$تایی اخیر بدانیم،‌ $f(A)$ برابر نزدیک‌ترین داده‌ی ۱ی است که در پنجره وجود دارد.

حال اگر بسته‌هایی را در نظر می‌گیریم که در هر کدام تعدادی از داده‌ها وجود دارد. به جای نگه‌داری تمام داده‌ها در بسته مجموع داده‌های ۱ آن بسته را نگه‌داری می‌کنیم (همان تابع $f$). برای بسته‌ای که مقدار ۱‌های آن برابر $C$ است تقریب $\frac{c}{2}$ را برای داده‌های ۱ی که در پنجره‌ی $N$تایی اخیر وجود دارد در نظر می‌گیریم. مقدار خطای این ایده محاسبه می‌شود و از روی آن  یک الگوریتم $(1+\eps)$-تقریب برای تعداد داده‌های ۱ در پنجره‌ی $N$تایی اخیر داریم.

\زیرقسمت{محاسبه‌ی عرض و قطر نقاط در پنجره‌ی لغزان}
در این قسمت می‌خواهیم پژوهش‌های انجام‌شده برای محاسبه‌ی عرض و قطر نقاط در پنجره‌ی لغزان بپردازیم. با توجه به محدودیت‌های بسیار زیاد مدل‌های جویبار داده و پنجره‌ی لغزان اکثر مسائل هندسی مطرح‌شده در این مدل‌ها پاسخی تقریبی دارند و کران پایین تقریب آن‌ها بیش از ۱ است. به عنوان مثال در مدل پنجره‌ی لغزان مسئله‌ی عرض نقاط در ساده‌ترین حالت خود یعنی ۱-بعدی برای پاسخ دقیق نیازمند حافظه‌ی $\omega(N)$ است . 
در قسمت قبلی (مسائل بهینه‌سازی هندسی در مدل ایستا) روش‌های معمول حل این مساسل را (دقیق و تقریبی) بررسی کردیم.

پس از معرفی مدل پنجره‌ی لغزان توسط داتار و سارین در
\cite{datar2002maintaining}
فین‌باوم و سایرین در
\مرجع{feigenbaum2005computing}
مسائل هندسی را به این مدل و مدل جویبار داده‌ها آوردند. آن‌ها برای تقریب $O(1+\eps)$ قطر نقاط ۱-بعدی در مدل پنجره‌ی لغزان، کران پایین
$O(\frac{1}{\eps} log R log N)$
(که $R$ برابر نسبت بیش‌ترین فاصله‌ی نقاط به کم‌ترین آن‌ها است) را ثابت کردند. آن‌ها از ایده‌ی روش لگاریتمی \پاورقی{Logarithmic Method}   \مرجع{bentley1980decomposable} برای پیداکردن بزرگ‌ترین (و کوچک‌ترین) نقطه در فضای یک‌بعدی استفاده کردند. الگوریتم آن‌ها به این صورت بود که خوشه‌هایی از نقاط داخل پنجره (که اندازه‌ی هر خوشه از توان ۲ بود) می‌ساختند و اگر دو خوشه اندازه‌ی یکسان داشتند با یک‌دیگر ادغام می‌کردند. نکته‌ی کلیدی هر خوشه مرکز آن بود که باید جوان‌ترین نقطه‌ی خوشه باشد. بقیه‌ی نقاط داخل پوشه با فاصله‌های متناسب با تصاعد هندسی $(1+\eps)$ گرد\پاورقی{Round} می‌شدند. به این ترتیب تعداد نمایندگان نقاط (همان اعداد گرد‌شده) بسیار کم‌تر از تعداد نقاط اصلی بود.

یکی از کارهای مهم فین‌باوم و سایرین به دست آوردن حد پایین حافظه برای تقریب قطر $1+\eps$ در مدل پنجره‌ی لغزان بود. که ما قضیه‌ی نهایی پژوهش آن‌ها را در این‌جا می‌آوریم.
\شروع{قضیه}[فین‌باوم و سایرین \مرجع{feigenbaum2005computing}]
\برچسب{قضیه: کران‌قطر}
فرض کنید $R$ نسبت بیشینه‌ی قطر به کوچک‌ترین فاصله‌ی بیش از صفر بین هر دو نقطه‌ای در تمام پنجره‌ها باشد. در صورتی که داشته باشیم
$\log R \le \frac{3}{2} \eps \cdot n^{1-\delta}$
(به ازای $\delta$ ثابت)،
برای تقریب $1+\eps$ قطر نقاط یک خط (فضای ۱-بعدی) در مدل پنجره‌ی لغزان به اندازه‌ی $N$ نیازمند
$\Omega(\frac{1}{\eps} \log R \log N)$
بیت حافظه داریم. و در صورتی که داشته باشیم
$\log R \le \frac{3}{2} \eps \cdot n$
مرتبه‌ی حافظه برابر با
$\Omega(N)$
خواهد بود.
\پایان{قضیه}
چن و سجاد در
\مرجع{chan2006geometric}
الگوریتمی با حافظه‌ی کمینه‌ی \رجوع{قضیه: کران‌قطر} برای محاسبه‌ی عرض و قطر در فضای یک‌بعدی ارائه دادند.. چن و سجاد هم‌چنین راه حل خود را برای ابعاد بالاتر به وسیله‌ی $\eps$-هسته گسترش دادند. ایده‌‌ی اصلی آن‌ها برای کاهش حافظه‌ی نگه‌داری‌شده ساخت یک دنباله‌ی خلاصه‌شده \پاورقی{Summary Sequence} از نقاط در فضای یک‌بعدی بود.
\شروع{تعریف}[دنباله‌ی خلاصه‌شده چن و سجاد \مرجع{chan2006geometric}]
فرض کنید 
$Q = \langle q_1, q_2, \ldots , q_k \rangle$
یک زیردنباله از دنباله‌ی $P$ (نقاط داخل پنجره‌ی لغزان)  که
$q_1 < q_2 < \ldots < q_k$
است. فرض کنید 
$pred_Q(p)$
بزرگ‌ترین نقطه در $Q$ است که حداکثر برابر با $p$ و $succ_Q(p)$ کوچک‌ترین نقطه در $Q$ است که حداقل برابر با $p$ است. به $Q$ یک دنباله‌ی خلاصه‌شده از $P$ می‌گوییم اگر شرایط زیر را داشته باشد.
\شروع{فقرات}
\فقره{
مقادیر $q_i$ها به ترتیب نزولی زمان ورود باشند.
}
\فقره{
	به ازای هر $p \in P$ اگر $pred_Q(p)$ وجود داشته باشد نباید پیرتر از $p$ باشد.
}
\فقره{
	به ازای هر $p$ یا باید داشته باشیم
	$||p - pred_Q(p)|| \le \eps \Delta(P)$
	و یا
	$succ_Q(p)$
	نباید پیرتر از $p$ باشد.
}
\پایان{فقرات}
\پایان{تعریف}
باید به این نکته توجه کرد که دنباله‌ی خلاصه‌شده لزوما یکتا نیست. چن و سجاد برای این که کوچک‌ترین دنباله‌ی خلاصه‌شده را به دست بیاورند در زمان ورود دنباله‌ی موجود را اصلاح می‌کنند تا به حافظه‌ی
$\cO(\frac{1}{\eps} \log R)$
برسند.

قابلیت منحصر به فرد دنباله‌ی خلاصه‌شده در این است که مانند یک صف \پاورقی{Queue} مرتب عمل می‌کند. هر نقطه‌ی جدیدی که وارد می‌شود از ابتدای صف ($q_1$) وارد می‌شود و تا جایی پیش می‌رود که از نقطه‌ی بعدی صف کوچک‌تر باشد. هم‌چنین نقاط قبل از خودش را هم از صف خارج می‌کند. حال برای این که در یک پنجره بزرگ‌ترین نقطه را داشته باشیم کافی است به $q_k$ نگاه کنیم. زمانی که $q_k$ منقضی می‌شود نقطه‌ی $q_{k-1}$ بزرگ‌ترین نقطه‌ی معتبر بعد از آن است. علاوه بر این موضوع به خاطر ویژگی سوم دنباله‌ی خلاصه‌شده می‌توانیم نقاطی که خیلی به هم نزدیک هستند را هم حذف کنیم و فقط جوان‌ترین آن‌ها را نگه‌داری کنیم. به همین دلیل اندازه‌ی $Q$ از مرتبه‌ی 
$\cO(\log_{1+\eps}^{R})$
خواهد بود.

پس از این که مسئله‌ی قطر و عرض نقاط یک‌بعدی در پنجره‌ی لغزان تقریب $(1+\eps)$ زده شد، با استفاده از ایده‌ی $\eps$-هسته \مرجع{chan2004faster} (نگه‌داری تعدادی خطوط با زاویه‌ی بین حداکثر
$\arccos (\frac{1}{1+\eps})$
) 
مسئله‌ی قطر در فضاهای ابعاد ثابت نیز حل می‌شود. علاوه بر این چن و سجاد روشی برای محاسبه‌ی قطر نقاط در مدل پنجره‌ی لغزان در فضای هندسی با ابعاد بالا ارائه دادند. 
این الگوریتم دارای ضریب تقریب
$O(2^{m+2} -2 + \eps)$
و حافظه‌ی مصرفی از مرتبه‌ی
$O(N^{\frac{1}{m+1}} log R)$
است. 

همان‌طور که در قسمت‌های قبل اشاره کردیم محاسبه‌ی عرض مسئله‌ی نسبتا پیچیده‌ای است و حتی در مدل ایستا روش‌های کارآمدی برای حل آن وجود ندارد. چن و سجاد پس از تقریب عرض در فضای یک‌بعدی (که معادل قطر است) یک $\eps$-هسته در صفحه با هدف تقریب عرض ارائه دادند. یکی از مهم‌ترین ویژگی‌های $\eps$-هسته این است که علاوه بر این که مسئله‌ی عرض را تقریب می‌زند، مسائلی که به نحوی با نقاط خارجی وابسته هستند (مثل کوچک‌ترین کره‌ی محیطی) را نیز می‌تواند تقریب بزند. حافظه‌ی مصرفی این $\eps$-هسته از مرتبه‌ی 
$ \cO(\frac{1}{\eps^2} log^3 N \log R polylog(R', N, \frac{1}{\eps})$
است که مقدار $R'$ برابر با عرض هر سه نقطه‌ی متوالی در تمامی پنجره‌ها است. اثبات می‌شود که کران پایین حافظه برای حل مسئله‌ی عرض به مقدار $\log R'$ وابسته است \مرجع{chan2006geometric}.

تا این‌جا تمامی پژوهش‌های انجام‌شده در فضای هندسی و ابعاد پایین بود. به تازگی کهن‌ادد و سایرین در \مرجع{DBLP:conf/icalp/Cohen-AddadSS16} الگوریتمی برای تقریب قطر در فضای متریک الگوریتمی با ضریب تقریب $3 + \eps$ ارائه دادند. علاوه بر این ثابت کردند در فضای متریک هر الگوریتم  $(3-\eps)$-تقریبی برای این مسئله نیاز به حافظه‌ی $O(N^\frac{1}{3})$ دارد.

آن‌ها رویکرد جدیدی برای حل مسئله‌ی قطر اتخاذ کردند. در کارهای فین‌باوم و سایرین \مرجع{feigenbaum2005computing} و چن و سجاد \مرجع{chan2006geometric} ایده‌ی اصلی حل مسئله در فضای یک‌بعدی و گسترش آن به فضاهای دیگر بود. به عبارت دیگر، اندازه‌ی قطر در الگوریتم آن‌ها تاثیری نداشت. کهن‌ادد و سایرین به جای تمرکز روی ابعاد پایین روی تقسیم بازه‌های پاسخ متمرکز شدند. آن‌ها زیرالگوریتم‌هایی برای حل مسئله در بازه‌های کوچک 
$ [\, \gamma, 3 \gamma)$
ایجاد کردند سپس با ایجاد بازه‌هایی که از یک‌دیگر به نسبت $(1+\eps)$ فاصله داشتند نسبت به تقریب پاسخ اصلی اقدام کردند.

نکته‌ی کلیدی الگوریتم آن‌ها در نگه‌داری یک  یا دو مرکز داخل پنجره است تا بتواند تشخیص دهد آیا پاسخ در این بازه قرار دارد.  در صورتی که یک مرکز داشته باشیم، فاصله‌ی هر دو نقطه‌ی پیرتر از  مرکز با یک‌دیگر حداکثر $2 \gamma$ و فاصله‌ی مرکز با نقاط بعد از خودش حداکثر $\gamma$ خواهد بود. به این ترتیب به خاطر ویژگی نامساوی مثلثاتی فاصله‌ی هر دو نقطه‌ای از یک‌دیگر حداکثر برابر با $3 \gamma$ خواهد شد. در صورتی که دو مرکز داشته باشیم فاصله‌ی آن دو بیش از $2 \gamma$ است و در این حالت پاسخ در بازه‌ی مورد نظر قرار ندارد. الگوریتم کوهن‌ادد و سایرین به ازای هر بازه حافظه‌ی $O(1)$ مصرف می‌کند.

حال الگوریتمی داریم که اگر قطر در محدوده‌ی مورد نظر باشد پاسخ بله و در غیر این صورت پاسخ خیر می‌دهد. اگر فرض کنیم کوچک‌ترین قطر در بین تمام پنجره‌ها مقدار $m$ و بزرگ‌ترین آن مقدار $M$ باشد کافی است بازه‌ی 
$ [\,m, M]\,$
را به بازه‌های کوچک‌تر با فاصله‌ی $(1+\eps) $ تقسیم کنیم. به طور دقیق‌تر بازه‌ی $i$ام معادل است با
$ [\, m (1+\eps)^i, 3 m (1+ \eps)^i )$
که تعداد بازه‌ها برابر می‌‌شود با 
$ \log_{1+\eps}^{\frac{M}{m}}$
. می‌دانیم
$\frac{M}{m} = \cO(R)$
پس مقدار حافظه‌ی کل این الگوریتم برابر با
$\cO(\frac{1}{\eps} \log R)$
خواهد بود.


\قسمت{$k$-مرکز‌ در مدل پنجره‌ی لغزان}
در این قسمت به بررسی مسئله‌ی $k$-مرکز در مدل‌های داده‌های حجیم می‌پردازیم. با توجه به این که پژوهش زیادی در مدل پنجره‌ی لغزان صورت نگرفته است ابتدا مقداری از تاریخچه‌ی $k$-مرکز در مدل جویبار داده می‌گوییم.

در مدل جویبار داده، مشکل اصلی عدم امکان نگه‌داری تمام داده‌ها در حافظه است و باید سعی شود تنها داده‌هایی را که ممکن است در ادامه مورد نیاز باشند نگه‌داریم.
یک روش معمول برای کاهش حافظه‌ی مصرفی، نگه‌داری مجموعه‌ای از نمایندگان نقاط اصلی است تا جواب مسئله‌ی $k$-مرکز را از آن به دست آوریم. قاعدتا به علت کاهش تعداد نقاط دقت پاسخ هم کاهش پیدا خواهد کرد. همان‌طور که در فصل قبل توضیح دادیم به چنین مجموعه‌ای، مجموعه‌ی هسته‌ی نقاط می‌گوییم.

در مدل جویبار داده بهترین مجموعه‌ی هسته برای حل مسئله‌ی $k$-مرکز توسط ضرابی‌زاده ارائه شده است \مرجع{zarrabi2008core}.  حافظه‌ی این مجموعه از مرتبه‌ی $\cO(\frac{k}{\epsilon^d})$ است. برای ایجاد این مجموعه‌ی هسته از دو ایده به صورت ترکیبی استفاده شده است. در گام اول از یک الگوریتم با ضریب تقریب ثابت استفاده می‌شود تا تخمینی از مراکز به دست بیاید. سپس نقاط حول هر مرکز را در یک توری با اندازه‌ی $\cO(\frac{1}{\epsilon})$  در هر بعد قرار می‌دهد. از این به بعد لزومی به نگه‌داری تمام داده‌ها نیست و سلول‌هایی که پر هستند می‌توانند به عنوان نمایندگان تمام نقاط استفاده شوند.

نمونه‌ای از اجرای الگوریتم ضرابی‌زاده در شکل \رجوع{شکل:توری} نشان داده شده است. \مرجع{hatami2015}.
برای دیدن اثبات‌ها و توضیح بیش‌تر در مورد روش ارائه شده می‌توانید به مرجع \مرجع{zarrabi2008core} مراجعه کنید.

\شروع{شکل}[ht]
\centerimg{zarrabi-zade-mesh-coreset}{10cm}
\شرح[نمونه‌ای از شبکه‌بندی الگوریتم ضرابی‌زاده]{نمونه‌ای از شبکه‌بندی الگوریتم ضرابی‌زاده (نقاط ضرب‌در شکل، مراکز به دست آمده از الگوریتم تقریبی است). پس از شبکه‌بندی کافی است برای هر کدام از خانه‌های شبکه‌بندی، تنها یکی را به عنوان نماینده در نظر بگیریم. \مرجع{hatami2015}}
\برچسب{شکل:توری}
\پایان{شکل}

در مدل پنجره‌ی لغزان پژوهش زیادی در رابطه با مسئله‌ی $k$-مرکز نشده است. تنها مقاله‌ای که الگوریتمی برای محاسبه‌ی $k$-مرکز ارائه داده است مقاله‌ی کهن‌ادد و سایرین \مرجع{DBLP:conf/icalp/Cohen-AddadSS16} است. رویکرد اصلی حل آن‌ها همانند محاسبه‌ی قطر متریک در مدل پنجره‌ی لغزان است. ضریب تقریب الگوریتم آن‌ها $6+\eps$ است.

در الگوریتم محاسبه‌ی قطر در فضای متریک، بازه‌ی پاسخ را به زیربازه‌هایی تقسیم کردند. سپس برای هر زیربازه یک زیرالگوریتم تعیین می‌کرد که آیا پاسخ (قطر) در این بازه قرار دارد یا ندارد. برای این که متوجه بشوند قطر یک دنباله خارج از بازه است کافی بود تنها دو نقطه که فاصله‌‌شان بیش از حد مشخصی باشد را نگه‌داری کنیم. در رابطه با چگونگی متوجه‌شدن این که پاسخ در بازه‌ی مرد نظر نیست، مسئله‌ی $k$-مرکز اندکی پیچیده‌تر است. زیرا اگر پاسخ خارج از بازه باشد باید حداقل $k+1$ نقطه‌ی دور از یک‌دیگر را نگه‌داری کرد. 

\شروع{الگوریتم}{الگوریتم محاسبه‌ی پاسخ $k$-مرکز در بازه‌ی مشخص در مدل پنجره‌ی لغزان}
\دستور{$\emptyset \rightarrow A, R, O$}
\به‌ازای{هر نقطه‌ی ورودی $p$ از جویبار داده}
\اگر{$q \in O$ منقضی شده‌ بود}
\دستور{$q$ را از $O$حذف کن.}
\پایان‌اگر{}
\اگر{$a \in A$ منقضی شده‌ بود}
\دستور{فرآیند 
	\lr{DeleteAttraction($a$)}
	را اجرا کن}
\پایان‌اگر{}
\دستور{فرآیند 
	\lr{Insert($p$)}
	را اجرا کن}
\پایان‌به‌ازای{}
\پایان{الگوریتم}

\شروع{الگوریتم}{رویه‌های الگوریتم محاسبه‌ی پاسخ $k$-مرکز در بازه‌ی مشخص در مدل پنجره‌ی لغزان}

\رویه{DeleteAttraction}{a}
\دستور{
$ O \cup \{R(a)\} \rightarrow O$
}
\دستور{
	$ R \setminus \{R(a)\} \rightarrow R$
}
\دستور{
	$ A \setminus \{a\} \rightarrow A$
}
\پایان‌رویه{}
\رویه{Insert}{p}
\State{$\{a \in A | dis(p, a) \le 2 \cdot \gamma\} \rightarrow D$}
\If{ $ D = \emptyset$}
\State{$ A \cup \{p\} \rightarrow A$}
\State{$ p \rightarrow R(p)$}
\State{$ R \cup \{R(p)\} \rightarrow R$}
\If{ $|A| > k+1$}
\State{$argmax_{a \in A} age(a) \rightarrow a_{old}$}
\State{$DeleteAttraction(a_{old})$}
\EndIf{}
\If{ $|A| > k$}
\State{$max_{a \in A} age(a) \rightarrow t$}
\به‌ازای{$q \in O$}
\If{$age(q) > t$}
\State{	$ O \setminus \{q\} \rightarrow O$}
\EndIf{}
\پایان‌به‌ازای{}
\EndIf{}
\Else{}
\به‌ازای{$a \in D$}
\State{	Exchange $R(a)$ with $p$ in $R$}
\پایان‌به‌ازای{}
\EndIf{}
\پایان‌رویه{}

\پایان{الگوریتم}


الگوریتم ارائه‌شده توسط کهن‌ادد و سایرین در الگوریتم \رجوع{الگوریتم: الگوریتم محاسبه‌ی پاسخ $k$-مرکز در بازه‌ی مشخص در مدل پنجره‌ی لغزان} قابل مشاهده است. این الگوریتم به طور کامل از  \مرجع{DBLP:conf/icalp/Cohen-AddadSS16} آورده شده است. مجموعه‌ی $A$ معادل مراکزی است که الگوریتم حدس می‌زند خوشه‌ها حول آن‌ها شکل می‌گیرند. اگر تعداد این مجموعه‌ها بیش از $k$ باشد یعنی حداقل $k+1$ نقطه در پنجره وجود دارد که فاصله‌شان بیش از حدی است که پاسخ $k$-مرکز در بازه‌ی مورد نظر باشد. مجموعه‌ی $R$ نماینده‌ی جوان‌ترین نقاطی است که در خوشه‌های با مرکزیت نقاط $A$ قرار دارند. مثلا اگر نقطه‌ای وارد شود که فاصله‌اش تا مرکزی کم‌تر از $2 \gamma$ باشد نماینده‌ی آن مرکز خواهد شد. نمایندگان مراکز از خود مراکز پیرتر نیستند. در نتیجه اگر مرکزی منقضی شود نماینده‌ی آن وجود دارد. پس از خروج مرکز، نماینده‌ی آن به مجموعه‌ی $O$ منتقل می‌شود که مجموعه‌ی نمایندگان یتیم \پاورقی{Orphan} است.
 
اندازه‌ی مجموعه‌های $A$ و $O$ و $R$ در الگوریتم \رجوع{الگوریتم: الگوریتم محاسبه‌ی پاسخ $k$-مرکز در بازه‌ی مشخص در مدل پنجره‌ی لغزان} از مرتبه‌ی 
$\cO(k)$
است. در نتیجه حافظه‌ی مصرفی هر الگوریتم $\cO(k)$ خواهد بود. با معرفی این الگوریتم تنها قسمت موازی‌سازی می‌ماند که کاملا مشابه قسمت موازی‌سازی در راه حل قطر است. یعنی بازه‌ی پاسخ را به بازه‌های
$ [\, m (1+\eps)^i, 6 m (1+ \eps)^i )$
تقسیم می‌کنند و برای هر زیربازه یک زیرالگوریتم \رجوع{الگوریتم: الگوریتم محاسبه‌ی پاسخ $k$-مرکز در بازه‌ی مشخص در مدل پنجره‌ی لغزان} اجرا می‌کنند.

در نتیجه حافظه‌ی الگوریتم محاسبه‌ی $k$-مرکز متریک در مدل پنجره‌ی لغزان ارائه‌شده توسط کهن‌ادد و سایرین از مرتبه‌ی
$\cO(k \frac{1}{\eps} \log R)$
است.

\زیرقسمت{جمع‌بندی}
در این فصل مسائل بهینه‌سازی هندسی در مدل‌های ایستا و پنجره‌ی لغزان را بررسی کردیم. میزان دقت الگوریتم‌هایی که برای مسائل بهینه‌سازی هندسی در مدل‌های مختلف ارائه‌ شده‌اند در جدول ~\رجوع{جدول:ضرایب تقریب بهینه‌سازی} و هم‌چنین میزان حافظه‌ی آن‌ها در جدول ~\رجوع{جدول:حافظه‌ی بهینه‌سازی} آمده است.\\

\شروع{لوح}[h]
\تنظیم‌ازوسط
\شروع{جدول}{|c|r|c|c|c|}
\خط‌پر 
\سیاه مسئله/مدل & \سیاه جویبار داده & \سیاه  پنجره‌ی لغزان & \سیاه  پ.ل. (ابعاد بالا) & \سیاه  گردان‌در \\ 
\خط‌پر 
عرض نقاط & 
$1 + \eps $\cite{agarwal2004approximating}
&
$ 1+ \eps$ (۲-بعدی) \cite{agarwal2004approximating}
& - & 
$1 + \eps$  \cite{chan2016dynamic}
\\
قطر نقاط & 
$1 + \eps $ \cite{agarwal2004approximating}
&
$1 + \eps $ \cite{chan2006geometric}
&
$ 3 + \eps $ \cite{DBLP:conf/icalp/Cohen-AddadSS16}
& 
$1 + \eps$  \cite{chan2016dynamic}
\\ 
$K$-مرکز
& 
$2 + \eps $\cite{zarrabi2008core} \cite{hochbaum1985best}
& $ 6 + \eps $\cite{DBLP:conf/icalp/Cohen-AddadSS16}  & 
$ 6 + \eps $\cite{DBLP:conf/icalp/Cohen-AddadSS16}
& -\\ 
$K$-میانه
&
$1 + \eps $ \cite{Babcock:2003:MVK:773153.773176}
& $O(1)$ \cite{braverman2016clustering} & 
$O(1)$ \cite{braverman2016clustering}
& - \\ 
\خط‌پر

\پایان{جدول}
\شرح[ضریب تقریب مسائل بهینه‌سازی هندسی در مدل‌های داده‌حجیم]{دقت الگوریتم‌های بهینه‌سازی هندسی در مدل‌های مختلف داده‌های حجیم}
\برچسب{جدول:ضرایب تقریب بهینه‌سازی}
\پایان{لوح}

‌\\

\شروع{لوح}[h]
\تنظیم‌ازوسط
\شروع{جدول}{|c|r|c|c|c|}
\خط‌پر 
\سیاه مسئله/مدل & \سیاه جویبار داده & \سیاه  پنجره‌ی لغزان & \سیاه  پ.ل. (ابعاد بالا) & \سیاه  مدل گردان‌در \\ 
\خط‌پر 
عرض نقاط & 
$\frac{(lg n)^d}{\eps ^ \frac{d-1}{2}}$
&
$polylog(N,R,R')$
& - & 
$(\frac{1}{\eps^{d+1}} (log U)^{3d+4} log (\frac{1}{\delta \eps})$
\\
قطر نقاط & 
$\frac{lg \frac{1}{\eps}}{\eps ^ \frac{d-1}{2}}$
&
$\eps^{-\frac{d+1}{2}} \frac{ln N ln R}{\eps}$
&
$ \frac{ln N ln R}{\eps}$
& 
$(\frac{1}{\eps^{d+1}}(log U)^{3d+4} log (\frac{1}{\delta \eps})$
\\ 
$K$-مرکز
& 
$\frac{k}{\eps^d}$
& $ k  \frac{ln N ln R}{\eps}$ & 
$ k  \frac{ln N ln R}{\eps}$
& -  \\ 
$K$-میانه
&
$\frac{k}{\eps^d} lg N$
& $k^3 log^6 N$ & 
$k^3 log^6 N$
& - \\ 
\خط‌پر

\پایان{جدول}
\شرح[حافظه‌ی بهینه‌سازی هندسی در مدل‌های داده‌حجیم]{میزان حافظه‌ی مورد نیاز الگوریتم‌های بهینه‌سازی هندسی در مدل‌های مختلف داده‌های حجیم}
\برچسب{جدول:حافظه‌ی بهینه‌سازی}
\پایان{لوح}

در این نتایج پژوهش‌های صورت‌گرفته در مدل گردان‌در را نیز آورده‌ایم. مدل گردان‌در از نظر ابعاد فضا ساده‌تر است (مختصات هر بعد عدد صحیح و بین $1$ تا $U$ است) اما امکان درج و حذف نقاط به صورت پویا را دارد. در صورتی که یک نقطه را پس از گذشت $N$ چرخه از ورودش حذف کنیم بسیار شبیه به مدل پنجره‌ی لغزان می‌شود. به همین دلیل مدل گردان‌در را نیز در مقایسه‌ی الگوریتم‌های مشابه آورده‌ایم تا دید بهتری پیدا کنیم. می‌توان گفت پارامتر $U$ در مدل گردان‌در شباهت بسیار زیادی به پارامتر $R$ در پنجره‌ی لغزان دارد.\\
