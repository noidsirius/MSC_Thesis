
\فصل{کارهای پیشین}

در این فصل کارهای پیشین انجام‌شده روی مسئله‌ی $k$-مرکز، در سه بخش مورد بررسی قرار می‌گیرد.
در بخش اول، مسائل قطر، عرض و $k$-مرکز در مدل ایستا مورد بررسی قرار می‌گیرد.
در بخش دوم، مسائل قطر و عرض در حالت پنجره‌ی لغزان و مجموعه هسته‌های مطرح برای این مسئله مورد بررسی قرار می‌گیرد و در نهایت، در بخش سوم، مسئله‌ی $k$-مرکز در مدل پنجره‌ی لغزان مورد بررسی قرار می‌گیرد.

\قسمت{مسائل بهینه‌سازی هندسی در مدل ایستا}

در این بخش می‌خواهیم مسائلی از بهینه‌سازی هندسی را در مدل ایستا بررسی کنیم که یا در هدف این پژوهش بوده‌اند (قطر و  $k$-مرکز) یا پژوهش مهمی در مدل پنجره‌ی لغزان آن شده است (عرض نقاط).

\زیرقسمت{قطر}
مسئله‌ی قطر در مدل ایستا معادل پیداکردن دورترین فاصله بین هر دو نقطه‌ای از $n$ نقطه‌ی ورودی است. ابتدایی‌ترین روش برای این مسئله مقایسه‌ی تمامی 
$ {{n}\choose{2}} $
مقدار ممکن است. برای فضای اقلیدسی $d$-بعدی کران پایین $\omega(n log n)$ ثابت شده است. \مرجع{preparata1985introduction} در فضای ۲-بعدی با استفاده از ایده‌ی پوش محدب می‌توان قطر را در مرتبه‌ی زمانی $O(n log n)$ به دست آورد. واضح است که نقاطی که قطر را تشکیل می‌دهند باید جزو رئوس پوش محدب باشند، پس با مرتبه‌ی زمانی $O(n log n)$ ابتدا پوش محدب را به دست می‌آوریم، سپس به ازای هر راس پوش محدب به وسیله‌ی جستجوی دودویی \پاورقی{ Binary Search} دورترین راس پوش را نسبت به آن راس به دست می‌آوریم. هم‌چنین محاسبه‌ی قطر در فضای ۲-بعدی کران پایین $\omega(n)$ را دارد. در فضای ۳-بعدی کار اندکی سخت‌تر است ولی الگوریتم با مرتبه‌ی زمانی $O( n log n)$ وجود دارد \مرجع{ramos2000deterministic}.

همان‌طور که دیده می‌شود روش‌های مسئله‌ی محاسبه‌ی قطر در ابعاد پایین مرتبه‌ی زمانی نزدیک به خطی دارند اما به علت این که برای ابعاد بالا روش کارآمدی وجود ندارد و حتی همین الگوریتم‌های ابعاد پایین با مرتبه‌ی خطی و زیرخطی فاصله دارند پژوهش‌هایی در راستای ارائه‌ی الگوریتم تقریبی برای قطر نقاط صورت گرفته است. یک الگوریتم تقریبی نسبتا بدیهی ۲-تقریب با مرتبه‌ی زمانی $O(dn)$ وجود دارد که یک نقطه را می‌گیرد و دورترین نقطه نسبت به آن را پیدا می‌کند، قطر از ۲ برابر این مقدار قطعا کوچک‌تر است پس ۲ برابر این مقدار یک ۲-تقریب برای قطر به شمار می‌آید. در ادامه یک الگوریتم $\sqrt{3}$-تقریب برای محاسبه‌ی قطر در $d$-بعد ارائه شده است \مرجع{eg̃eciog̃lu1989approximating}. تلاش‌هایی برای ارائه‌ی الگوریتم $(1 + O(\epsilon))$-تقریب هم صورت گرفته است که به علت مرتبه‌ی زمانی نسبتا بالا دیگر به آن نمی‌پردازیم.

\زیرقسمت{عرض}
مفهوم عرض نقاط در فضا $d$-بعدی به صورت رسمی در \رجوع{تعریف:عرض} تعریف شد. می‌توانیم مسئله‌ی عرض را به نحوه‌ی دیگری نیز بیان کرد که ملموس‌تر است.
\شروع{تعریف}
\مهم{عرض نقاط:} مجموعه‌ی $P$ شامل تعدادی نقاط $d$-بعدی است. دو صفحه\پاورقی{Hyperplane} موازی را به نام‌های $HP_1$ و $HP_2$ در نظر بگیرید که تمامی نقاط $P$ بین این دو صفحه قرار دارد. به کم‌ترین فاصله‌ی بین هر دو صفحه عرض نقاط می‌گوییم و با $w(P)$ نمایش می‌دهیم.
\پایان{تعریف}
  همان‌طور که در قسمت قطر گفته شد می‌توان در فضای ۲-بعدی عرض نقاط را به صورت دقیق در زمان $O(n log n)$ به دست آورد \مرجع{preparata1985introduction}. محاسبه‌ی عرض نقاط در ابعاد بالاتر به سادگی محاسبه‌ی قطر نیست. در فضای ۳-بعدی اولین الگوریتمی که برای حل دقیق ارائه شد مرتبه‌ی زمانی $O(n^2)$ داشت \مرجع{houle1988computing}. ایده‌ی این الگوریتم از تکنیک چرخاندن کولیس \پاورقی{‌Rotating Calipers} به دست می‌آید. علت نام‌گذاری این روش شباهت آن به اندازه‌گیری یک جسم چندوجهی به وسیله‌ی کولیس است که وقتی یک بازوی کولیس با یک یال چندوجهی تماس پیدا می‌کند بازوی دیگر به یک نقطه‌ی چندوجهی می‌رسد که این دو نقطه، جفت پادپایی \پاورقی{Antipodal Pair} هستند. به وسیله‌ی چرخاندن چندوجهی می‌توان تمام جفت‌های پادپایی را شناسایی کرد که فاصله‌ی کوچک‌ترین آن‌ها برابر با عرض خواهد بود \مرجع{preparata1985introduction}. برای ابعاد بالاتر روشی با مرتبه‌ی زمانی
   $O(n^{\lfloor \frac{d}{2} \rfloor})$
وجود دارد \مرجع{clarkson1989applications}.

یکی از مهم‌ترین پیش‌رفت‌ها در الگوریتم‌های تقریبی هندسی در حوزه‌ی محاسبه‌ی عرض نقاط به وجود آمده است. معرفی ایده‌ی $\epsilon$-هسته علاوه بر این که بستری برای کاهش حجم نقاط ورودی با کاهش دقت در تقریب $(1+ \epsilon)$ ایجاد کرد، ابزار بسیار قدرتمندی برای حل مسائل بهینه‌سازی هندسی در مدل‌های جویبار داده به شمار آمد. قبل از $\epsilon$-هسته روش‌هایی برای محاسبه‌ی عرض نقاط با تقریب  $(1+ \epsilon)$  ارائه شده بود \مرجع{duncan1999efficient} اما مرتبه‌ی زمانی بالایی مصرف می‌کرد و پیچیده بود که در پژوهش‌های دیگری سعی کردند این موارد را بهبود دادند \مرجع{chan2000approximating}. 
نوید: آيا $\epsilon$-هسته به طور کامل توضیح داده بشه؟
\زیرقسمت{$k$-مرکز}
(شروع:بهنام)
مسئله‌ی $k$-مرکز به عنوان مسئله‌ای شناخته شده در علوم کامپیوتر مطرح است.
این مسئله، در واقع یک مسئله‌ی بهینه‌سازی است که سعی در کاهش بیش‌ترین فاصله نقاط از مرکز دسته‌ها را دارد.
سختی اصلی این مسئله در انتخاب مرکز دسته‌هاست.
زیرا اگر بتوانیم مرکز دسته‌ها را به درستی تشخیص دهیم، کافی است هر نقطه را به دسته‌ای که نزدیک‌ترین مرکز را دارد، تخصیص دهیم.
به وضوح چنین تخصیصی، تخصیص بهینه‌ای است.
نمونه‌ای از این تخصیص را در شکل \رجوع{شکل:تخصیص‌نقاط} نشان داده شده است.

\شروع{شکل}[ht]
\centerimg{point-assignment}{10cm}
\شرح{نمونه‌ای از تخصیص نقاط‌ به ازای مراکز مربع شکل توخالی.}
\برچسب{شکل:تخصیص‌نقاط}
\پایان{شکل}

در سال $1979$، نه تنها اثبات گردید که این مسئله در حالت کلی یک مسئله‌ی ان‌پی-سخت است \مرجع{michael1979computers}، بلکه در سال $1984$ ثابت شده است که این مسئله در صفحه‌ی دو بعدی با معیار فاصله‌ی اقلیدسی نیز ان‌پی-سخت است \مرجع{megiddo1984complexity}.
فراتر از این، ثابت شده است که برای مسئله‌ی $k$-مرکز با متریک دلخواه هیچ الگوریتم تقریبی با ضریب تقریب بهتر از $2$ وجود ندارد.

ایده‌ی اصلی این کران پایین، کاهش مسئله‌ی پوشش رأسی، به مسئله‌ی $k$-مرکز است.
برای چنین کاهشی کافی است، از روی گراف اصلی که می‌خواهیم کوچک‌ترین مجموعه‌ی پوشش رأسی را در آن پیدا کنیم، یک گراف کامل بسازیم به طوری که به ازای هر یال در گراف اصلی، یک یال با وزن یک و به ازای هر یال که در گراف اصلی وجود ندارد، یک یال با وزن $2$ قرار دهیم.
نمونه‌ای از چنین تبدیلی را در شکل \رجوع{شکل:کاهش‌ ۲-مرکز} می‌توانید مشاهده کنید.
حال اگر الگوریتمی بتواند مسئله‌ی $k$-مرکز را با ضریب تقریب بهتر از $2$ حل نماید، آن گاه گراف جدید دارای یک $k$-مرکز با شعاع کم‌تر از $2$ است، اگر و تنها اگر گراف اصلی دارای یک پوشش رأسی با اندازه‌ی $k$ باشد.
برای متریک $L_2$ یا فضای اقلیدسی\پاورقی{Euclidean space} نیز ثابت شده است برای مسئله‌ی $k$-مرکز، الگوریتم تقریبی با ضریب تقریب بهتر از $1.822$ وجود ندارد \مرجع{bern1996approximation}.

\شروع{شکل}[ht]
\centerimg{k-center-reduction}{10cm}
\شرح[نمونه‌ای از تبدیل ورودی مسئله‌ی پوشش‌ رأسی به ورودی مسئله‌ی $k$-مرکز]{نمونه‌ای از تبدیل یک گراف ورودی مسئله‌ی پوشش‌ رأسی به یک ورودی مسئله‌ی $k$-مرکز(در گراف سمت چپ، یال‌های سیاه وزن $1$ و یال‌های خط‌چین، وزن $2$ دارند)}
\برچسب{شکل:کاهش‌ ۲-مرکز}
\پایان{شکل}

\شروع{الگوریتم}{الگوریتم گنزالز}
\ورودی{$V$ مجموعه نقاط‌ و $k$ تعداد مرکز دسته‌ها}
\دستور{$S$ را برابر مجموعه تهی قرار بده.}
\دستور{عنصر دلخواه از مجموعه نقاط $V$ را به $S$ اضافه کن.}
\به‌ازای{$i$ بین $2$ تا $k$}
\دستور{$v$ را نقطه‌ای از $V$ در نظر بگیرید که بیش‌ترین فاصله را از مجموعه‌ی $S$ دارد.}
\دستور{$v$ را به $S$ اضافه کن.}
\پایان‌به‌ازای
\دستور{$S$ را برگردان}
\پایان{الگوریتم}

یکی از اولین الگوریتم‌های تقریبی برای مسئله‌ی $k$-مرکز به وسیله‌ی گنزالز\پاورقی{Gonzalez} ارائه شده است \مرجع{gonzalez1985clustering}. این الگوریتم یک الگوریتم تقریبی با ضریب ۲ است و در زمان $\cO(kn)$ قابل اجراست. الگوریتم گنزالز، از نظر روش برخورد با مسئله، یک الگوریتم حریصانه\پاورقی{Greedy} محسوب می‌شود. برای بیان نحوه‌ی عملکرد الگوریتم گنزالز، نیاز به تعریف فاصله‌ی یک نقطه از یک مجموعه نقطه داریم.

\شروع{تعریف}
فاصله‌ی نقطه‌ی $v$ از مجموعه‌ای ناتهی از نقاط $S$ را برابر فاصله‌ی نقطه‌ای درون $S$ از $v$ تعریف می‌کنیم، به‌گونه‌ای که از تمام نقاط $S$ به $v$ نزدیک‌تر باشد. در واقع داریم:
$$d(v, S) = \min_{u \in S} \set{ d(u, v) }$$
\پایان{تعریف}

همان‌طور که در الگوریتم ~\رجوع{الگوریتم: الگوریتم گنزالز} مشاهده می‌کنید، روش اجرای این الگوریتم به این گونه است که در ابتدا یک نقطه‌ی دلخواه را به عنوان مرکز دسته‌ی اول در نظر می‌گیرد.
سپس دورترین نقطه از آن را به عنوان مرکز دسته‌ی دوم در نظر می‌گیرد.
در هر مرحله، دورترین نقطه از مرکز مجموعه دسته‌های انتخاب شده را به عنوان مرکز دسته‌ی جدید به مجموعه مراکز دسته‌ها اضافه می‌کند.
با اجرای الگوریتم تا $k$ مرحله، مراکز دسته‌ها انتخاب می‌شوند.
حال اگر هر نقطه را به نزدیک‌ترین مرکز انتخابی تخصیص دهیم، می‌توان نشان داد که شعاع بزرگ‌ترین دسته، حداکثر دو برابر شعاع بهینه برای مسئله‌ی $k$-مرکز است.
نمونه‌ای از اجرای الگوریتم گنزالز، در شکل \رجوع{شکل:گنزالز} نشان داده شده است.

\شروع{شکل}[ht]
\centerimg{Gonzalez}{10cm}
\شرح{نمونه‌ای از حل مسئله‌ی ۳-مرکز با الگوریتم گنزالز}
\برچسب{شکل:گنزالز}
\پایان{شکل}

تا به اینجا، تنها بر روی حالت کلی مسئله‌ی $k$-مرکز صحبت شد و تنها محدودیتی که مورد توجه قرار گرفت، متریک مطرح برای فاصله‌ی نقاط بوده است.
در ادامه به بررسی، حالاتی از مسئله‌ی $k$ -مرکز، که $k$ تعداد دسته‌ها یا $d$ ابعاد فضا ثابت باشند می‌پردازیم.
آگاروال\پاورقی{Agarwal} و سایرین الگوریتمی دقیق با زمان اجرای $n^{\cO(k^{1 - \frac{1}{d}})}$ برای مسئله $k$-مرکز در فضای $L_p$-متریک با ابعاد ثابت $d$ ارائه داده‌اند \مرجع{agarwal2002exact}.
قابل توجه است که اگر $d$ ثابت نباشد، مسئله‌ی $k$-مرکز حتی برای متریک اقلیدسی ($L_2$-متریک) با تعداد دسته‌ی ثابت $k \geq 2$، ان‌پی-سخت است \مرجع{megiddo1990complexity}.

علاوه بر حالاتی که ابعاد فضا یا تعداد دسته‌ها ثابت‌اند، مسئله‌ی $k$-مرکز برای حالتی که مقادیر $k$ و $d$ کوچک هستند، مورد بررسی قرار گرفته‌اند و الگوریتم‌های بهتری از الگوریتم‌های کلی برای این حالت‌های خاص ارائه شده است.
به طور مثال، برای مسئله‌ی $1$-مرکز در فضای اقلیدسی با ابعاد ثابت، الگوریتم خطی با زمان اجرای $\cO((d+1)! n)$ وجود دارد \مرجع{chazelle1996linear}.
الگوریتم ارائه شده بر پایه‌ی دو نکته‌ی اساسی بنا شده است.
اول اینکه کره‌ی بهینه را می‌توان با حداکثر $d+1$ نقطه‌ی واقع در پوسته‌ی کره‌ی بهینه مشخص نمود و دوم اینکه اگر نقاط ورودی را با ترتیبی تصادفی پیمایش کنیم احتمال اینکه نقطه‌ی پیمایش شده جزء نقاط مرزی باشد از مرتبه‌ی $\cO(\frac{d}{n})$ است که با توجه به ثابت بودن $d$ این احتمال برای $n$های بزرگ کوچک محسوب می‌شود و زمان اجرای الگوریتم، به طور میانگین خطی خواهد بود. 


برای متریک اقلیدسی در دو بعد برای مسئله‌ی $2$-مرکز, بهترین الگوریتم را چن\پاورقی{Chan} با زمان اجرای $\cO(n \log^2{n} \log^2{\log{n}})$ و حافظه‌ی $\cO(n)$ ارائه داده است \مرجع{chan1999more}.
برای فضای سه‌بعدی اقلیدسی نیز آگاروال و سایرین، الگوریتمی با متوسط زمان اجرای $\cO(n^3\log^8{n})$ ارائه داده است \مرجع{agarwal20132}.
(پایان:بهنام)

\قسمت{تاریخچه‌ی مدل پنجره‌ی لغزان}
می‌توان گفت مدل پنجره‌ی لغزان در دو مسیر متفاوت در علوم محاسباتی پیشرفت کرد. مسیر اول رویکرد آماری به مسائل بود که خود مدل پنجره‌ی لغزان را معرفی کرد و در مسیر دوم مسائل بهینه‌سازی هندسی بودند که از آمار فاصله گرفتند. به علت اهمیت مسئله‌ی $k$-مرکز در مدر پنجره‌ی لغزان، این مسئله را در یک قسمت جدا بررسی خواهیم کرد.
\زیرقسمت{مسائل آماری در پنجره‌ی لغزان}
مدل پنجره‌ی لغزان سال ۲۰۰۲ در \مرجع{datar2002maintaining}
توسط داتار و سایرین ارائه شد. آن‌ها با ارائه‌ی بستر هیستوگرام نمایی \پاورقی{Exponential Histogram} ابتدا مسئله‌ی شمارش ساده را حل کردند سپس با تعمیم آن به مسئله‌ی جمع (مجموع $N$ داده‌ی اخیر) خانواده‌ی توابعی را معرفی کردند که به وسیله‌ی بستر هیستوگرام نمایی می‌توان با تقریب $O(1+\eps)$ و سربار حافظه‌ی $O(\frac{1}{\eps} log N)$ آن‌‌ها را محاسبه کرد. این مقاله علاوه بر این که مدل پنجره‌ی لغزان را معرفی کرد، بستر بسیار مناسبی برای مدل‌سازی مسائل دیگر ارائه داد. مسائل ساده‌ی آماری مانند میانگین در این مقاله به طور کامل پوشش داده شد، بابکوک و سایرین در \مرجع{Babcock:2003:MVK:773153.773176} این روند را ادامه دادند و مسائل واریانس و $K$-میانه \پاورقی{$K-Means$} را حل کردند. فضای حافظه‌ی الگوریتم آن‌ها برای مسئله‌ی $K$-میانه برابر
$O(\frac{k}{\tau^4}N^{2\tau} log^2 N)$
به ازای $ \tau < \frac{1}{2}$  و تقریب
$O(2^{O(\frac{1}{\tau})})$
بود. در این مقاله‌ی مسئله‌ی بازی مطرح شد که «آیا الگوریتمی برای مسئله‌ی $K$-میانه وجود دارد که مرتبه‌ی حافظه‌ی آن نسبت به اندازه‌ی پنجره لگاریتمی باشد؟». این مسئله در دو مرحله توسط بریورمن و سایرین حل شد. ابتدا آن‌ها در \مرجع{braverman2010effective}
  هیستوگرام نمایی را هم از نظر دقت تقریب و هم از نظر عمومیت خانواده‌ی توابعی که پشتیبانی می‌کند پیشرفت دادند و نام هیستوگرام ملایم \پاورقی{\lr{Smooth Histogram}} روی آن نهادند. سپس با استفاده از این بستر جدید در  \مرجع{braverman2016clustering}
توانستند مسئله‌ی باز مطرح‌شده $K$-میانه در \مرجع{Babcock:2003:MVK:773153.773176}
را با حافظه‌ی $ O(k^3 log^6 N)$ حل کنند.
حال مسئله‌ی مهمی از این حوزه که پایه‌ی روش‌های دیگر به حساب می‌آید را به طور دقیق‌تر بررسی می‌کنیم.
\زیرزیرقسمت{شمارش ساده}
مدل پنجره‌ی لغزان با معرفی این مسئله شروع شد که منجر به معرفی خانواده‌ای از توابع شد که به وسیله‌ی بستر‌ آن‌ها قابل محاسبه در مدل پنجره‌ی لغزان بود. خانواده‌ی توابع $f$ و مجموعه‌های $A$ و $B$ از داده‌ها را در نظر بگیرید که

\شروع{فقرات}
\item $f(A) \ge 0$
\item $f(A) \le poly(|A|)$
\item $f(A \cup B) \ge f(A) + f(B)$
\item $f(A \cup B) \le C_f (f(A) + f(B))$
\پایان{فقرات}
در عبارات بالا در نظر بگیرید که $C_f$ یک عدد ثابت است که تنها به تابع $f$ وابسته است.

در مسئله‌ی شمارش ساده، داده‌ها اعداد ۰ یا ۱ هستند و می‌خواهیم تعداد داده‌ی ۱ در پنجره‌ی $N$تایی اخیر را بشماریم. برای این مسئله، تابع $f$ را این گونه تعریف می‌کنیم که $f(A) $ برابر است با شماره‌ی نزدیک‌ترین داده‌ی ۱ در مجموعه‌ی $A$. به عنوان مثال اگر $A$ را داده‌های پنجره‌ی $N$تایی اخیر بدانیم،‌ $f(A)$ برابر نزدیک‌ترین داده‌ی ۱ی است که در پنجره وجود دارد.

حال اگر بسته‌هایی را در نظر می‌گیریم که در هر کدام تعدادی از داده‌ها وجود دارد. به جای نگه‌داری تمام داده‌ها در بسته مجموع داده‌های ۱ آن بسته را نگه‌داری می‌کنیم (همان تابع $f$). برای بسته‌ای که مقدار ۱‌های آن برابر $C$ است تقریب $\frac{c}{2}$ را برای داده‌های ۱ی که در پنجره‌ی $N$تایی اخیر وجود دارد در نظر می‌گیریم. مقدار خطای این ایده محاسبه می‌شود و از روی آن  یک الگوریتم $(1+\eps)$-تقریب برای تعداد داده‌های ۱ در پنجره‌ی $N$تایی اخیر داریم.

\زیرقسمت{محاسبه‌ی عرض و قطر نقاط در پنجره‌ی لغزان}
در این قسمت می‌خواهیم پژوهش‌های انجام‌شده برای محاسبه‌ی عرض و قطر نقاط در پنجره‌ی لغزان بپردازیم. با توجه به محدودیت‌های بسیار زیاد مدل‌های جویبار داده و پنجره‌ی لغزان اکثر مسائل هندسی مطرح‌شده در این مدل‌ها پاسخی تقریبی دارند و کران پایین تقریب آن‌ها بیش از ۱ است. به عنوان مثال در مدل پنجره‌ی لغزان مسئله‌ی عرض نقاط در ساده‌ترین حالت خود یعنی ۱-بعدی برای پاسخ دقیق نیازمند حافظه‌ی $\omega(N)$ است . 
در قسمت قبلی (مسائل بهینه‌سازی هندسی در مدل ایستا) روش‌های معمول حل این مساسل را (دقیق و تقریبی) بررسی کردیم.

پس از معرفی مدل پنجره‌ی لغزان توسط داتار و سارین در
\cite{datar2002maintaining}
فین‌باوم و سایرین در
\مرجع{feigenbaum2005computing}
مسائل هندسی را به این مدل و مدل جویبار داده‌ها آوردند. آن‌ها برای تقریب $O(1+\eps)$ قطر نقاط ۱-بعدی در مدل پنجره‌ی لغزان، کران پایین
$O(\frac{1}{\eps} log R log N)$
(که $R$ برابر نسبت بیش‌ترین فاصله‌ی نقاط به کم‌ترین آن‌ها است) را ثابت کردند. آن‌ها از ایده‌ی روش لگاریتمی \پاورقی{Logarithmic Method}   \مرجع{bentley1980decomposable} برای پیداکردن بزرگ‌ترین (و کوچک‌ترین) نقطه در فضای یک‌بعدی استفاده کردند. الگوریتم آن‌ها به این صورت بود که خوشه‌هایی از نقاط داخل پنجره (که اندازه‌ی هر خوشه از توان ۲ بود) می‌ساختند و اگر دو خوشه اندازه‌ی یکسان داشتند با یک‌دیگر ادغام می‌کردند. نکته‌ی کلیدی هر خوشه مرکز آن بود که باید جوان‌ترین نقطه‌ی خوشه باشد. بقیه‌ی نقاط داخل پوشه با فاصله‌های متناسب با تصاعد هندسی $(1+\eps)$ گرد\پاورقی{Round} می‌شدند. به این ترتیب تعداد نمایندگان نقاط (همان اعداد گرد‌شده) بسیار کم‌تر از تعداد نقاط اصلی بود.

یکی از کارهای مهم فین‌باوم و سایرین به دست آوردن حد پایین حافظه برای تقریب قطر $1+\eps$ در مدل پنجره‌ی لغزان بود. که ما قضیه‌ی نهایی پژوهش آن‌ها را در این‌جا می‌آوریم.
\شروع{قضیه}[فین‌باوم و سایرین \مرجع{feigenbaum2005computing}]
\برچسب{قضیه: کران‌قطر}
فرض کنید $R$ نسبت بیشینه‌ی قطر به کوچک‌ترین فاصله‌ی بیش از صفر بین هر دو نقطه‌ای در تمام پنجره‌ها باشد. در صورتی که داشته باشیم
$\log R \le \frac{3}{2} \eps \cdot n^{1-\delta}$
(به ازای $\delta$ ثابت)،
برای تقریب $1+\eps$ قطر نقاط یک خط (فضای ۱-بعدی) در مدل پنجره‌ی لغزان به اندازه‌ی $N$ نیازمند
$\Omega(\frac{1}{\eps} \log R \log N)$
بیت حافظه داریم. و در صورتی که داشته باشیم
$\log R \le \frac{3}{2} \eps \cdot n$
مرتبه‌ی حافظه برابر با
$\Omega(N)$
خواهد بود.
\پایان{قضیه}
چن و سجاد در
\مرجع{chan2006geometric}
الگوریتمی با حافظه‌ی کمینه‌ی \رجوع{قضیه: کران‌قطر} برای محاسبه‌ی عرض و قطر در فضای یک‌بعدی ارائه دادند.. چن و سجاد هم‌چنین راه حل خود را برای ابعاد بالاتر به وسیله‌ی $\eps$-هسته گسترش دادند. ایده‌‌ی اصلی آن‌ها برای کاهش حافظه‌ی نگه‌داری‌شده ساخت یک دنباله‌ی خلاصه‌شده \پاورقی{Summary Sequence} از نقاط در فضای یک‌بعدی بود.
\شروع{تعریف}[دنباله‌ی خلاصه‌شده چن و سجاد \مرجع{chan2006geometric}]
فرض کنید 
$Q = \langle q_1, q_2, \ldots , q_k \rangle$
یک زیردنباله از دنباله‌ی $P$ (نقاط داخل پنجره‌ی لغزان)  که
$q_1 < q_2 < \ldots < q_k$
است. فرض کنید 
$pred_Q(p)$
بزرگ‌ترین نقطه در $Q$ است که حداکثر برابر با $p$ و $succ_Q(p)$ کوچک‌ترین نقطه در $Q$ است که حداقل برابر با $p$ است. به $Q$ یک دنباله‌ی خلاصه‌شده از $P$ می‌گوییم اگر شرایط زیر را داشته باشد.
\شروع{فقرات}
\فقره{
مقادیر $q_i$ها به ترتیب نزولی زمان ورود باشند.
}
\فقره{
	به ازای هر $p \in P$ اگر $pred_Q(p)$ وجود داشته باشد نباید پیرتر از $p$ باشد.
}
\فقره{
	به ازای هر $p$ یا باید داشته باشیم
	$||p - pred_Q(p)|| \le \eps \Delta(P)$
	و یا
	$succ_Q(p)$
	نباید پیرتر از $p$ باشد.
}
\پایان{فقرات}
\پایان{تعریف}
باید به این نکته توجه کرد که دنباله‌ی خلاصه‌شده لزوما یکتا نیست. چن و سجاد برای این که کوچک‌ترین دنباله‌ی خلاصه‌شده را به دست بیاورند در زمان ورود دنباله‌ی موجود را اصلاح می‌کنند تا به حافظه‌ی
$\cO(\frac{1}{\eps} \log R)$
برسند.

قابلیت منحصر به فرد دنباله‌ی خلاصه‌شده در این است که مانند یک صف \پاورقی{Queue} مرتب عمل می‌کند. هر نقطه‌ی جدیدی که وارد می‌شود از ابتدای صف ($q_1$) وارد می‌شود و تا جایی پیش می‌رود که از نقطه‌ی بعدی صف کوچک‌تر باشد. هم‌چنین نقاط قبل از خودش را هم از صف خارج می‌کند. حال برای این که در یک پنجره بزرگ‌ترین نقطه را داشته باشیم کافی است به $q_k$ نگاه کنیم. زمانی که $q_k$ منقضی می‌شود نقطه‌ی $q_{k-1}$ بزرگ‌ترین نقطه‌ی معتبر بعد از آن است. علاوه بر این موضوع به خاطر ویژگی سوم دنباله‌ی خلاصه‌شده می‌توانیم نقاطی که خیلی به هم نزدیک هستند را هم حذف کنیم و فقط جوان‌ترین آن‌ها را نگه‌داری کنیم. به همین دلیل اندازه‌ی $Q$ از مرتبه‌ی 
$\cO(\log_{1+\eps}^{R})$
خواهد بود.

پس از این که مسئله‌ی قطر و عرض نقاط یک‌بعدی در پنجره‌ی لغزان تقریب $(1+\eps)$ زده شد، با استفاده از ایده‌ی $\eps$-هسته \مرجع{chan2004faster} (نگه‌داری تعدادی خطوط با زاویه‌ی بین حداکثر
$\arccos (\frac{1}{1+\eps})$
) 
مسئله‌ی قطر در فضاهای ابعاد ثابت نیز حل می‌شود. علاوه بر این چن و سجاد روشی برای محاسبه‌ی قطر نقاط در مدل پنجره‌ی لغزان در فضای هندسی با ابعاد بالا ارائه دادند. 
این الگوریتم دارای ضریب تقریب
$O(2^{m+2} -2 + \eps)$
و حافظه‌ی مصرفی از مرتبه‌ی
$O(N^{\frac{1}{m+1}} log R)$
است. 

همان‌طور که در قسمت‌های قبل اشاره کردیم محاسبه‌ی عرض مسئله‌ی نسبتا پیچیده‌ای است و حتی در مدل ایستا روش‌های کارآمدی برای حل آن وجود ندارد. چن و سجاد پس از تقریب عرض در فضای یک‌بعدی (که معادل قطر است) یک $\eps$-هسته در صفحه با هدف تقریب عرض ارائه دادند. یکی از مهم‌ترین ویژگی‌های $\eps$-هسته این است که علاوه بر این که مسئله‌ی عرض را تقریب می‌زند، مسائلی که به نحوی با نقاط خارجی وابسته هستند (مثل کره‌ی محصور کمینه) را نیز می‌تواند تقریب بزند. حافظه‌ی مصرفی این $\eps$-هسته از مرتبه‌ی 
$ \cO(\frac{1}{\eps^2} log^3 N \log R polylog(R', N, \frac{1}{\eps})$
است که مقدار $R'$ برابر با عرض هر سه نقطه‌ی متوالی در تمامی پنجره‌ها است. اثبات می‌شود که کران پایین حافظه برای حل مسئله‌ی عرض به مقدار $\log R'$ وابسته است \مرجع{chan2006geometric}.

تا این‌جا تمامی پژوهش‌های انجام‌شده در فضای هندسی و ابعاد پایین بود. به تازگی کهن‌ادد و سایرین در \مرجع{DBLP:conf/icalp/Cohen-AddadSS16} الگوریتمی برای تقریب قطر در فضای متریک الگوریتمی با ضریب تقریب $3 + \eps$ ارائه دادند. علاوه بر این ثابت کردند در فضای متریک هر الگوریتم  $(3-\eps)$-تقریبی برای این مسئله نیاز به حافظه‌ی $O(N^\frac{1}{3})$ دارد.

آن‌ها رویکرد جدیدی برای حل مسئله‌ی قطر اتخاذ کردند. در کارهای فین‌باوم و سایرین \مرجع{feigenbaum2005computing} و چن و سجاد \مرجع{chan2006geometric} ایده‌ی اصلی حل مسئله در فضای یک‌بعدی و گسترش آن به فضاهای دیگر بود. به عبارت دیگر، اندازه‌ی قطر در الگوریتم آن‌ها تاثیری نداشت. کهن‌ادد و سایرین به جای تمرکز روی ابعاد پایین روی تقسیم بازه‌های پاسخ متمرکز شدند. آن‌ها زیرالگوریتم‌هایی برای حل مسئله در بازه‌های کوچک 
$ [\, \gamma, 3 \gamma)$
ایجاد کردند سپس با ایجاد بازه‌هایی که از یک‌دیگر به نسبت $(1+\eps)$ فاصله داشتند نسبت به تقریب پاسخ اصلی اقدام کردند.

نکته‌ی کلیدی الگوریتم آن‌ها در نگه‌داری یک  یا دو مرکز داخل پنجره است تا بتواند تشخیص دهد آیا پاسخ در این بازه قرار دارد.  در صورتی که یک مرکز داشته باشیم، فاصله‌ی هر دو نقطه‌ی پیرتر از  مرکز با یک‌دیگر حداکثر $2 \gamma$ و فاصله‌ی مرکز با نقاط بعد از خودش حداکثر $\gamma$ خواهد بود. به این ترتیب به خاطر ویژگی نامساوی مثلثاتی فاصله‌ی هر دو نقطه‌ای از یک‌دیگر حداکثر برابر با $3 \gamma$ خواهد شد. در صورتی که دو مرکز داشته باشیم فاصله‌ی آن دو بیش از $2 \gamma$ است و در این حالت پاسخ در بازه‌ی مورد نظر قرار ندارد. الگوریتم کوهن‌ادد و سایرین به ازای هر بازه حافظه‌ی $O(1)$ مصرف می‌کند.

حال الگوریتمی داریم که اگر قطر در محدوده‌ی مورد نظر باشد پاسخ بله و در غیر این صورت پاسخ خیر می‌دهد. اگر فرض کنیم کوچک‌ترین قطر در بین تمام پنجره‌ها مقدار $m$ و بزرگ‌ترین آن مقدار $M$ باشد کافی است بازه‌ی 
$ [\,m, M]\,$
را به بازه‌های کوچک‌تر با فاصله‌ی $(1+\eps) $ تقسیم کنیم. به طور دقیق‌تر بازه‌ی $i$ام معادل است با
$ [\, m (1+\eps)^i, 3 m (1+ \eps)^i )$
که تعداد بازه‌ها برابر می‌‌شود با 
$ \log_{1+\eps}^{\frac{M}{m}}$
. می‌دانیم
$\frac{M}{m} = \cO(R)$
پس مقدار حافظه‌ی کل این الگوریتم برابر با
$\cO(\frac{1}{\eps} \log R)$
خواهد بود.


\قسمت{$k$-مرکز‌ در حالت پنجره‌ی لغزان}
(شروع:بهنام)
در مدل جویبار داده، مشکل اصلی عدم امکان نگه‌داری تمام داده‌ها در حافظه است و باید سعی شود تنها داده‌هایی را که ممکن است در ادامه مورد نیاز باشند نگه‌داریم.
یکی از راه‌های رایج برای این کار نگه‌داری مجموعه‌ای از نقاط (نه لزوماً زیرمجموعه‌ای از نقاط ورودی) به عنوان نماینده‌ی نقاط است به‌طوری‌که جواب مسئله‌ی $k$-مرکز برای آن‌ها منطبق با جواب مسئله‌ی $k$-مرکز برای نقاط اصلی باشد (با تقریب قابل قبولی).
به چنین مجموعه‌ای مجموعه‌ی هسته‌ی نقاط گفته می‌شود. 

بهترین مجموعه هسته‌ای که برای مسئله‌ی $k$-مرکز در مدل جویبار داده ارائه شده است، روش ارائه‌شده به وسیله‌ی ضرابی‌زاده برای نگه‌داری یک $\epsilon$-هسته با حافظه‌ی $\cO(\frac{k}{\epsilon^d})$ برای $L_p$-متریک‌ها است \مرجع{zarrabi2008core}.
در روش ارائه شده، از چند ایده‌ی ترکیبی استفاده شده است. 

در ابتدا، الگوریتم با استفاده از یک الگوریتم تقریبی با ضریب ثابت، یک تقریب از جواب بهینه به دست می‌آورد.
به طور مثال با استفاده از الگوریتم گنزالز، یک $2$-تقریب از شعاع بهینه به علاوه‌ی مرکز دسته‌های پیدا شده را به دست می‌آورد.
حال با استفاده از طول شعاع الگوریتم تقریبی، حول هر مرکز، یک توری با $\cO(\frac{1}{\epsilon})$ شبکه‌بندی در هر بعد تشکیل می‌دهد و چون هر نقطه در حداقل یکی از توری‌ها قرار می‌گیرد، می‌توان با حداکثر $\epsilon$ تقریب در جواب نهایی نقاط را به نقاط شبکه‌بندی توری گرد نمود.
با این کار، دیگر نیازی به نگهداری تمام نقاط ورودی نبوده و تنها نقاط شبکه‌بندی توری نگهداری می‌شود.
با این روش می‌توان به یک $\epsilon$-هسته برای مسئله‌ی $k$-مرکز رسید. 

نکته‌ی اساسی برای سازگار سازی روش ارائه‌شده با مدل جویبار داده‌ی تک‌گذره استفاده از روش دوبرابرسازی\پاورقی{Doubling} رایج در الگوریتم‌های جویبار داده است.
نمونه‌ای از اجرای الگوریتم ضرابی‌زاده در شکل \رجوع{شکل:توری} نشان داده شده است.
برای دیدن اثبات‌ها و توضیح بیش‌تر در مورد روش ارائه شده می‌توانید به مرجع \مرجع{zarrabi2008core} مراجعه کنید.

\شروع{شکل}[ht]
\centerimg{zarrabi-zade-mesh-coreset}{10cm}
\شرح[نمونه‌ای از شبکه‌بندی الگوریتم ضرابی‌زاده]{نمونه‌ای از شبکه‌بندی الگوریتم ضرابی‌زاده (نقاط ضرب‌در شکل، مراکز به دست آمده از الگوریتم تقریبی است). پس از شبکه‌بندی کافی است برای هر کدام از خانه‌های شبکه‌بندی، تنها یکی را به عنوان نماینده در نظر بگیریم.}
\برچسب{شکل:توری}
\پایان{شکل}

تا به اینجا ما به بررسی مسئله‌ی $k$-مرکز در حالت جویبار داده بدون محدودیت خاصی پرداختیم.
برای مقادیر کوچک $k$، به خصوص $1$ و $2$، مسئله‌ی $k$-مرکز با متریک اقلیدسی مورد بررسی زیادی قرار گرفته است و راه‌حل‌های بهتری نسبت به حالت کلی برای آن‌ها پیشنهاد شده است.
به طور مثال، می‌توان یک هسته با اندازه‌ی $\cO(\frac{1}{\epsilon^{\frac{d-1}{2}}})$, با استفاده از نقاط حدی\پاورقی{Extreme points} در تعداد مناسبی جهت، به صورت جویبار داده ساخت. 

در مدل پنجره‌ی لغزان پژوهش زیادی در رابطه با مسئله‌ی $k$-مرکز نشده است. تنها مقاله‌ای که الگوریتمی برای محاسبه‌ی $k$-مرکز ارائه داده است مقاله‌ی کهن‌ادد و سایرین \مرجع{DBLP:conf/icalp/Cohen-AddadSS16} است. رویکرد اصلی حل آن‌ها همانند محاسبه‌ی قطر متریک در مدل پنجره‌ی لغزان است. ضریب تقریب الگوریتم آن‌ها $6+\eps$ است.

در الگوریتم محاسبه‌ی قطر در فضای متریک، بازه‌ی پاسخ را به زیربازه‌هایی تقسیم کردند.سپس برای هر زیربازه یک زیرالگوریتم تعیین می‌کرد که آیا پاسخ (قطر) در این بازه قرار دارد یا ندارد. برای این که متوجه بشوند قطر یک دنباله خارج از بازه است کافی بود تنها دو نقطه که فاصله‌‌شان بیش از حد مشخصی باشد را نگه‌داری کنیم. در رابطه با چگونگی متوجه‌شدن این که پاسخ در بازه‌ی مرد نظر نیست، مسئله‌ی $k$-مرکز اندکی پیچیده‌تر است. زیرا اگر پاسخ خارج از بازه باشد باید حداقل $k+1$ نقطه‌ی دور از یک‌دیگر را نگه‌داری کرد. 

\شروع{الگوریتم}{متریکkمرکز}
\caption
{الگوریتم محاسبه‌ی پاسخ $k$-مرکز در بازه‌ی $(\gamma, 6 \gamma) $در مدل پنجره‌ی لغزان \مرجع{DBLP:conf/icalp/Cohen-AddadSS16}}
\دستور{$\emptyset \rightarrow A, R, O$}
\به‌ازای{هر نقطه‌ی ورودی $p$ از جویبار داده}
\اگر{$q \in O$ منقضی شده‌ بود}
\دستور{$q$ را از $O$حذف کن.}
\پایان‌اگر{}
\اگر{$a \in A$ منقضی شده‌ بود}
\دستور{فرآیند 
	\lr{DeleteAttraction($a$)}
	را اجرا کن}
\پایان‌اگر{}
\دستور{فرآیند 
	\lr{Insert($p$)}
	را اجرا کن}
\پایان‌به‌ازای{}
\پایان{الگوریتم}

\شروع{الگوریتم}{رویهkمرکز}
\caption
{رویه‌های الگوریتم محاسبه‌ی پاسخ $k$-مرکز در بازه‌ی $(\gamma, 6 \gamma) $در مدل پنجره‌ی لغزان}

\رویه{DeleteAttraction}{a}
\دستور{
$ O \cup \{R(a)\} \rightarrow O$
}
\دستور{
	$ R \setminus \{R(a)\} \rightarrow R$
}
\دستور{
	$ A \setminus \{a\} \rightarrow A$
}
\پایان‌رویه{}
\رویه{Insert}{p}
\State{$\{a \in A | dis(p, a) \le 2 \cdot \gamma\} \rightarrow D$}
\If{ $ D = \emptyset$}
\State{$ A \cup \{p\} \rightarrow A$}
\State{$ p \rightarrow R(p)$}
\State{$ R \cup \{R(p)\} \rightarrow R$}
\If{ $|A| > k+1$}
\State{$argmax_{a \in A} age(a) \rightarrow a_{old}$}
\State{$DeleteAttraction(a_{old})$}
\EndIf{}
\If{ $|A| > k$}
\State{$max_{a \in A} age(a) \rightarrow t$}
\به‌ازای{$q \in O$}
\If{$age(q) > t$}
\State{	$ O \setminus \{q\} \rightarrow O$}
\EndIf{}
\پایان‌به‌ازای{}
\EndIf{}
\Else{}
\به‌ازای{$a \in D$}
\State{	Exchange $R(a)$ with $p$ in $R$}
\پایان‌به‌ازای{}
\EndIf{}
\پایان‌رویه{}

\پایان{الگوریتم}


الگوریتم ارائه‌شده توسط کهن‌ادد و سایرین در الگوریتم \رجوع{الگوریتم: متریکkمرکز} قابل مشاهده است. مجموعه‌ی $A$ معادل مراکزی است که الگوریتم حدس می‌زند خوشه‌ها حول آن‌ها شکل می‌گیرند. اگر تعداد این مجموعه‌ها بیش از $k$ باشد یعنی حداقل $k+1$ نقطه در پنجره وجود دارد که فاصله‌شان بیش از حدی است که پاسخ $k$-مرکز در بازه‌ی مورد نظر باشد. مجموعه‌ی $R$ نماینده‌ی جوان‌ترین نقاطی است که در خوشه‌های با مرکزیت نقاط $A$ قرار دارند. مثلا اگر نقطه‌ای وارد شود که فاصله‌اش تا مرکزی کم‌تر از $2 \gamma$ باشد نماینده‌ی آن مرکز خواهد شد. نمایندگان مراکز از خود مراکز پیرتر نیستند. در نتیجه اگر مرکزی منقضی شود نماینده‌ی آن وجود دارد. پس از خروج مرکز، نماینده‌ی آن به مجموعه‌ی $O$ منتقل می‌شود که مجموعه‌ی نمایندگان یتیم \پاورقی{Orphan} است.
 
اندازه‌ی مجموعه‌های $A$ و $O$ و $R$ در الگوریتم \رجوع{الگوریتم: متریکkمرکز} از مرتبه‌ی 
$\cO(k)$
است. در نتیجه حافظه‌ی مصرفی هر الگوریتم $\cO(k)$ خواهد بود. با معرفی این الگوریتم تنها قسمت موازی‌سازی می‌ماند که کاملا مشابه قسمت موازی‌سازی در راه حل قطر است. یعنی بازه‌ی پاسخ را به بازه‌های
$ [\, m (1+\eps)^i, 6 m (1+ \eps)^i )$
تقسیم می‌کنند و برای هر زیربازه یک زیرالگوریتم \رجوع{الگوریتم: متریکkمرکز} اجرا می‌کنند.

در نتیجه حافظه‌ی الگوریتم محاسبه‌ی $k$-مرکز متریک در مدل پنجره‌ی لغزان ارائه‌شده توسط کهن‌ادد و سایرین از مرتبه‌ی
$\cO(k \frac{1}{\eps} \log R)$
است.


در این فصل مسائل بهینه‌سازی هندسی در مدل‌های ایستا و پنجره‌ی لغزان را بررسی کردیم. میزان دقت الگوریتم‌هایی که برای مسائل بهینه‌سازی هندسی در مدل‌های مختلف ارائه‌ شده‌اند در جدول ~\رجوع{جدول:ضرایب تقریب بهینه‌سازی} و هم‌چنین میزان حافظه‌ی آن‌ها در جدول ~\رجوع{جدول:حافظه‌ی بهینه‌سازی} آمده است.\\

\شروع{لوح}[h]
\تنظیم‌ازوسط
\شروع{جدول}{|c|r|c|c|c|}
\خط‌پر 
\سیاه مسئله/مدل & \سیاه جویبار داده & \سیاه  پنجره‌ی لغزان & \سیاه  پنجره‌ی لغزان (ابعاد بالا) & \سیاه  مدل گردان‌در \\ 
\خط‌پر 
عرض نقاط & 
$1 + \eps $\cite{agarwal2004approximating}
&
$ 1+ \eps$ (۲-بعدی) \cite{agarwal2004approximating}
& - & 
$1 + \eps$  \cite{chan2016dynamic}
\\
قطر نقاط & 
$1 + \eps $ \cite{agarwal2004approximating}
&
$1 + \eps $ \cite{chan2006geometric}
&
$ 3 + \eps $ \cite{DBLP:conf/icalp/Cohen-AddadSS16}
& 
$1 + \eps$  \cite{chan2016dynamic}
\\ 
$K$-مرکز
& 
$2 + \eps $\cite{zarrabi2008core} \cite{hochbaum1985best}
& $ 6 + \eps $\cite{DBLP:conf/icalp/Cohen-AddadSS16}  & 
$ 6 + \eps $\cite{DBLP:conf/icalp/Cohen-AddadSS16}
& -\\ 
$K$-میانه
&
$1 + \eps $ \cite{Babcock:2003:MVK:773153.773176}
& $O(1)$ \cite{braverman2016clustering} & 
$O(1)$ \cite{braverman2016clustering}
& - \\ 
\خط‌پر

\پایان{جدول}
\شرح{دقت الگوریتم‌های بهینه‌سازی هندسی در مدل‌های مختلف داده‌های حجیم}
\برچسب{جدول:ضرایب تقریب بهینه‌سازی}
\پایان{لوح}
در این نتایج پژوهش‌های صورت‌گرفته در مدل گردان‌در را نیز آورده‌ایم. مدل گردان‌در از نظر ابعاد فضا ساده‌تر است (مختصات هر بعد عدد صحیح و بین $1$ تا $U$ است) اما امکان درج و حذف نقاط به صورت پویا را دارد. در صورتی که یک نقطه را پس از گذشت $N$ چرخه از ورودش حذف کنیم بسیار شبیه به مدل پنجره‌ی لغزان می‌شود. به همین دلیل مدل گردان‌در را نیز در مقایسه‌ی الگوریتم‌های مشابه آورده‌ایم تا دید بهتری پیدا کنیم. می‌توان گفت پارامتر $U$ در مدل گردان‌در شباهت بسیار زیادی به پارامتر $R$ در پنجره‌ی لغزان دارد.\\

\شروع{لوح}[h]
\تنظیم‌ازوسط
\شروع{جدول}{|c|r|c|c|c|}
\خط‌پر 
\سیاه مسئله/مدل & \سیاه جویبار داده & \سیاه  پنجره‌ی لغزان & \سیاه  پنجره‌ی لغزان (ابعاد بالا) & \سیاه  مدل گردان‌در \\ 
\خط‌پر 
عرض نقاط & 
$\frac{(lg n)^d}{\eps ^ \frac{d-1}{2}}$
&
$polylog(N,R,R')$ (۲-بعدی)
& - & 
$(\eps ^{-(d+1)} (log U)^{3d+4} log (\frac{1}{\delta \eps})$
\\
قطر نقاط & 
$\frac{lg \frac{1}{\eps}}{\eps ^ \frac{d-1}{2}}$
&
$\eps^{-\frac{d+1}{2}} \frac{ln N ln R}{\eps}$
&
$ \frac{ln N ln R}{\eps}$
& 
$(\eps ^{-(d+1)} (log U)^{3d+4} log (\frac{1}{\delta \eps})$
\\ 
$K$-مرکز
& 
$\frac{k}{\eps^d}$
& $ k  \frac{ln N ln R}{\eps}$ & 
$ k  \frac{ln N ln R}{\eps}$
& -  \\ 
$K$-میانه
&
$\frac{k}{\eps^d} lg N$
& $k^3 log^6 N$ & 
$k^3 log^6 N$
& - \\ 
\خط‌پر

\پایان{جدول}
\شرح{میزان حافظه‌ی مورد نیاز الگوریتم‌های بهینه‌سازی هندسی در مدل‌های مختلف داده‌های حجیم}
\برچسب{جدول:حافظه‌ی بهینه‌سازی}
\پایان{لوح}

