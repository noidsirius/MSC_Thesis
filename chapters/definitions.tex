
\فصل{مفاهیم اولیه}

در این فصل به تعریف و بیان مفاهیم پایه‌ای مورد استفاده در فصل‌های بعد می‌پردازیم.
با توجه به مطالب مورد نیاز در فصل‌های آتی، مطالب این فصل به سه بخش، مسائل بهینه‌سازی هندسی، الگوریتم‌های پنجره‌های لغزان و الگوریتم‌های تقریبی تقسیم می‌شود.

\قسمت{مسائل بهینه‌سازی هندسی}

همان‌طور که در مقدمه گفته شد، مسائل بهینه‌سازی هندسی از مسائل بسیار قدیمی علوم کامپیوتر به شمار می‌آیند. شاید از معروف‌ترین و پرکاربردترین این بهینه‌سازی‌ها به مسئله‌ی پوش محدب اشاره کرد که هدف آن کمینه‌کردن محیط یک چندضلعی است که تمامی نقاط ورودی را پوشش دهد. مسائل بهینه‌سای هندسی را می‌توان در فضای متریک یا اقلیدسی تعریف کرد. به عنوان مثال مسئله‌ی پوش محدب تنها در فضای اقلیدسی تعریف می‌شود اما مسئله‌ی $k$-مرکز در هر دو فضای متریک و اقلیدسی قابل تعریف است. برای بررسی بیش‌تر فضای متریک و اقلیدسی را تعریف می‌کنیم.
\شروع{تعریف}
فضای متریک: به مجموعه‌ی نقاط $M$ و تابع متریک $d$ به صورت
$$ d: M \times M \to \mathbb{R}$$
  فضای متریک می‌گوییم اگر به ازای 
  $x, y, z \in M$
  خواص زیر را داشته باشد. 
\شروع{فقرات}
\item{$ d(x,y) = 0 \iff x = y $}
\item{$ d(x,y) = d(y,x) $}
\item{$ d(x,y) + d(y,z) \ge d(x,z)$ : \lr{Triangle Inequality}}

\پایان{فقرات}
\پایان{تعریف}
\شروع{تعریف}
اگر مجموعه‌ی نقاط ($M$) فضای متریک معادل نقاط $d$-بعدی باشد (یا یک بردار $d$-متغیره که هر کدام یک عدد حقیقی هستند) و تابع متریک آن $L_2$ باشد (رجوع به تعریف $L_P$-متریک \رجوع{تعریف:LP}) آن فضا یک فضای اقلیدسی است. 
\پایان{تعریف}
با کمی بررسی می‌توان متوجه شد که تابع $L_2$ خواص تعریف‌شده در فضای متریک را ارضا می‌کند. در نتیجه هر روشی که برای فضای متریک ارائه می‌شود قابل اجرا در فضای اقلیدسی است اما عکس آن صادق نیست. یکی از نکات مفید فضای اقلیدسی دامنه‌ی بزرگ مجموعه‌‌ی مرجع $M$ و محدودیت موجود در تابع متریک آن است. از طرف دیگر بسیاری از مسائل دنیای واقعی (مثل نقشه‌های زمینی ۲-بعدی، طراحی‌های ۳-بعدی) در فضای اقلیدسی قرار دارند که باعث می‌شود کاربرد زیادی در مسائل هندسی داشته باشد.

یکی از تکنیک‌های موجود برای دسته‌بندی نقاط در فضای اقلیدسی \مهم{شبکه‌بندی}\پاورقی{Grid} است. در این روش محورها را با خطوطی موازی و با فاصله‌ی (معمولا) برابر تقسیم می‌کنند و در نتیجه فضای $d$-بعدی به جعبه‌هایی با عرض مساوی در هر محور تقسیم می‌شود و هر نقطه به راحتی به یک جعبه اختصاص می‌یابد. از فواید این روش کاهش حجم داده‌ها به هزینه‌ی کاهش دقت در محاسبات است.

برخی از مسائل بهینه‌سازی هندسی (مانند $k$-مرکز، $k$-میانه یا $k$-میانگین) رویکردهایی برای حل مسائل خوشه‌بندی است. این روش‌ها به طور معمول در مدل خوشه‌بندی‌های مرکزگرا با تخصیص قطعی داده هستند.  اهداف این سه نوع مسئله را در زیر آورده‌ایم
\شروع{فقرات}
\فقره{هدف خوشه‌بندی $k$-مرکز شناسایی $k$ نقطه است که اگر نقاط ورودی را بر حسب نزدیک‌ترین فاصله به این مراکز دسته‌بندی کنیم، ‌بیش‌ترین فاصله‌ی هر نقطه‌ی ورودی با مرکز دسته‌‌اش کمینه شود.} \فقره{در خوشه‌بندی $k$-میانه، هدف دسته‌بندی نقاط به $k$ دسته است به نحوی که مجموع مربع فاصله‌ی هر نقطه از میانه‌ی نقاط آن دسته، کمینه شود. }
\فقره{تمرکز خوشه‌بندی $k$-میانگین روی متوسط فاصله‌ی نقاط با مرکز دسته‌شان است. در خوشه‌بندی $k$-میانگین، هدف افراز نقاط به $k$ خوشه است به گونه‌ای که مجموع فاصله‌ی هر نقطه از میانگین نقاط داخل خوشه (یا مرکز آن خوشه) کمینه گردد.}
\پایان{فقرات}
همان‌طور که از تعریف مسئله‌ها به نظر می‌رسد، $k$-میانه و $k$-میانگین بیش‌تر رویکردی آماری دارند و $k$-مرکز به مباحث هندسی نزدیک‌تر است. به همین دلیل تمرکز اصلی این پژوهش روی مسئله‌ی $k$-مرکز است.

یکی از مسائلی که شباهت زیادی به مسئله‌ی $1$-مرکز دارد مسئله‌ی کوچک‌ترین کره‌ی محیطی است. این مسئله را به صورت رسمی تعریف می‌کنیم.
\شروع{تعریف}[کوچک‌ترین کره‌ی محیطی]

مجموعه‌ی نقاط $P$ را در نظر بگیرید. $\text{\lr{Meb}}(P)$ را برابر توپی با کوچک‌ترین شعاع تعریف می‌کنیم که تمام نقاط $P$ را می‌پوشاند.

\پایان{تعریف}
\قسمت{الگوریتم‌های پنجره‌ی لغزان}
روز به روز با مسائل بیش‌تری رو به رو می‌شویم که داده‌ها به مرور در حال تولید هستند و به دنبال پاسخ‌دهی به مسئله‌ای روی داده‌های موجود هستیم. به همین دلیل مدل‌های جدیدی برای برخورد مناسب با این مسائل معرفی می‌شود که در آن ورودی به مرور زمان در اختیار الگوریتم قرار می‌گیرد.
با توجه به این که معمولا حجم اطلاعات ورودی بسیار بالاست نمی‌توان داده‌ها را به طور کامل ذخیره کرد تا در آینده از آن استفاده کنیم.  نتیجه‌ی این امر باعث می‌شود الگوریتم‌ها در این مدل‌ها تنها امکان دسترسی یک یا چندباره به اطلاعات از طریق پویش\پاورقی{scan} آن از ابتدای ورودی تا انتهای ورودی وجود دارد. یکی از معروف‌ترین این مدل‌ها مدل جویبار داده است.

در واقع الگوریتم‌های جویبار داده، به الگوریتم‌هایی گفته می‌شوند که ورودی آن‌ها یک یا چند دنباله است که الگوریتم می‌تواند به ترتیب دنباله، یک یا چند بار از ابتدای دنباله تا انتهای آن، به اعضای دنباله دسترسی داشته باشد.

مدل‌های مختلفی شبیه به جویبار داده برای پاسخ به چنین محدودیت‌هایی به وجود آمده‌اند که در این‌جا به ۳ مدل جویبار داده، پنجره‌ی لغزان و گردان‌در اشاره می‌کنیم.
\شروع{تعریف}
\مهم{جویبار داده:} در این مدل داده‌ها یکی پس از دیگری وارد می‌شوند و ترتیب ورود داده‌ها مشخص نیست. تفاوت این مدل با مدل برخط این است که امکان نگه‌داری تمامی داده‌هایی که تا الان وارد شده‌اند را نداریم و حافظه از مرتبه‌ی برخطی است. الگوریتم‌های این مدل دو عمل زیر را انجام می‌دهند:
\شروع{فقرات}
\فقره{به روز رسانی: در این عمل نقطه‌ی جدید وارد می‌شود. الگوریتم باید آن را پردازش کند و با توجه به محدودیت حافظه عملیاتی را اجرا کند.}
\فقره{ پرسمان: در این عمل از الگوریتم درخواست می‌شود تا پاسخ مسئله‌ی مورد نظر را برای تمام نقاطی که تا الان آمده‌اند خروجی دهد.}
\پایان{فقرات}
\پایان{تعریف}
\شروع{تعریف}
\مهم{پنجره‌ی لغزان:} این مدل از مدل جویبار داده مشتق شده است و تنها تفاوت آن در عملیاتی است که انجام می‌دهد.
\شروع{فقرات}
\فقره{به روز رسانی: در این عمل نقطه‌ی جدید وارد پنجره می‌شود. الگوریتم باید آن را پردازش کند و با توجه به محدودیت حافظه عملیاتی را اجرا کند.}
\فقره{منقضی‌شدن یک نقطه: در این عمل نقطه‌ای که قبلا وارد پنجره شده است منقضی می‌شود و به قولی از پنجره خارج می‌شود. توجه شود که همیشه پیرترین نقطه می‌تواند منقضی شود و نمی‌توان نقطه‌ای جوان‌تر را از پنجره خارج کرد.}
\فقره{ پرسمان: در این عمل از الگوریتم درخواست می‌شود تا پاسخ مسئله‌ی مورد نظر را برای تمام نقاط معتبر (داخل پنجره) که وارد شده‌اند و منقضی نشده‌اند خروجی دهد.}
\پایان{فقرات}
\پایان{تعریف}
منقضی‌شدن نقطه در مدل پنجره‌ی لغزان می‌تواند از دو روش صورت بگیرد. در روش اول پنجره را ثابت در نظر می‌گیریم و برای آن ظرفیت تعیین می‌کنیم (مثلا $N$ نقطه). در این حالت پس از ورود $N$ نقطه، به ازای هر ورود (به روزرسانی) یک عمل منقضی‌شدن نقطه هم خواهیم داشت. در روشی دیگر پس از گذشت مقدار زمانی یک نقطه منقضی می‌شود. در مثال \رجوع{مثال:اینستاگرام} داستان‌های اینستاگرام پس از گذشت ۲۴ ساعت از محاسبات خارج می‌شدند یا به قولی عملیات منقضی‌شدن داده اجرا می‌شد.
\شروع{تعریف}
\مهم{گردان‌در:} این مدل گونه‌ای از مدل جویبار داده‌ی پویا است. نقاط ورودی مختصات صحیح \پاورقی{Integer} و محدود دارند (مختصات هر محور در مجموعه‌ی 
$ \{ 0, \cdots, U-1\}$ 
قرار دارند) و عملیات زیر را انجام می‌دهند.
\شروع{فقرات}
\فقره{به روز رسانی: در این عمل نقطه‌ی جدید وارد می‌شود. این نقطه می‌تواند تکراری باشد، الگوریتم باید آن را پردازش کند و با توجه به محدودیت حافظه عملیاتی را اجرا کند.}
\فقره{حذف یک نقطه: در این عمل یک نقطه‌ حذف می‌شود. توجه شود که نمی‌توان نقطه‌ای را بیش از مقداری که اضافه شده است حذف کرد و هم‌چنین محدودیتی در انتخاب نقاط برای حذف وجود ندارد.}
\فقره{ پرسمان: در این عمل از الگوریتم درخواست می‌شود تا پاسخ مسئله‌ی مورد نظر را برای تمام نقاط معتبر (داخل پنجره) که وارد شده‌اند و منقضی نشده‌اند خروجی دهد.}
\پایان{فقرات}
\پایان{تعریف}
الگوریتم‌های مدل‌های بالا معمولاً محدودیت شدیدی در میزان حافظه دارند (نسبت به اندازه‌ی ورودی) و به علت تعداد زیاد داده‌ها، محدودیت زمانی پردازش برای هر داده نیز مطرح است. این محدودیت‌ها معمولاً باعث می‌شود که این الگوریتم‌ها تنها بتوانند یک جواب تقریبی از جواب بهینه را با استفاده از اطلاعات مختصری که در حافظه نگه می‌دارد ارائه دهد.

با پیشرفت‌های سخت‌افزاری، امکان ایجاد و در عین حال جمع‌آوری داده‌ها به صورت مداوم بسیار آسان‌تر شده است. علاوه بر مثال‌هایی که در مقدمه اورده شد می‌توان به دیگر شبکه‌های اجتماعی، تلفن همراه یا بازی‌های بزرگ برخط اشاره کرد. ارتباط با این سیستم‌ها باعث ایجاد مقدار زیادی اطلاعات می‌شود و شرکت‌های بزرگ به دنبال استفاده از این داده‌ها برای سرویس‌دهی بهتر و یا شناسایی بازار مناسب خودشان هستند. زمانی که حجم تولید و دریافت داده‌ها به حدی باشد که امکان ذخیره‌سازی آن نیز وجود نداشته باشد به سراغ مدل‌های جویبار داده می‌رویم.

الگوریتم‌های جویبار داده بسیار با الگوریتم‌های برخط\پاورقی{Online }شباهت دارند. مهم‌ترین این شباهت‌ها عدم امکان دسترسی به تمام داده‌ها در شروع اجرای الگوریتم است. علاوه بر این شباهت تفاوت‌هایی با یک‌دیگر دارند. حافظه‌ی الگوریتم‌های جویبار داده بسیار محدود است که به طور معمول برای الگوریتم‌های برخط چنین محدودیتی وجود ندارد. از طرف دیگر الگوریتم‌های جویبار داده به پرسمان‌ها پاسخ می‌دهند که لزومی ندارد به ازای ورود هر داده پرسیده شود. اما الگوریتم‌های برخط به ازای هر ورود باید پاسخ پرسمان اصلی را بدهند.
هر جویبار را می‌توان به عنوان دنباله‌ای مرتب از نقاط در نظر گرفت به طوری که به ترتیب دنباله قابل دسترسی هستند و هر کدام را تنها به تعدادی محدود بار (معمولاً یک بار) می‌توان خواند \مرجع{aggarwal2007data}.
(بازنویسی:مسائل معروف پنجره‌ی لغزان)

\زیرقسمت{مجموعه هسته}
با توجه به این که محدودیت زیادی در حافظه در مدل جویبار داده و پنجره‌ی لغزان داریم نیاز به کاهش اطلاعات نگه‌داری‌شده یا به نحوی گزینش نقاط و گردکردن آن‌ها داریم.
در صورتی که مجموعه‌ای از نقاط یا نمایندگان آن‌ها را انتخاب کنیم که حجم بسیار کم‌تری از داده‌های اصلی دارند اما خطای اندکی ایجاد می‌کنند می‌توانیم به این محدودیت فائق آییم. به چنین مجموعه‌ای, مجموعه هسته می‌گوییم.

\شروع{تعریف}

فرض کنید $\mu$ یک تابع اندازه‌گیری\پاورقی{Measure function} باشد که نقاط فضای $d$-بعدی ‌( $\IR^d$ )را به اعداد حقیقی نامنفی $\IR^+ \cup \set{0}$ می‌نگارد (مثل تابع عرض مجموعه‌ای از نقاط). 
فرض کنید که این تابع، یک تابع یکنوا است، یعنی به ازای دو مجموعه‌ی  $P_1 \subset P_2$ داریم
$$\mu(P_1) \leq \mu(P_2)$$
فرض کنید $\epsilon > 0$ به عنوان پارامتر ورودی داده شده است، به زیرمجموعه‌ی $Q \subseteq P$ یک $\epsilon$-مجموعه‌ی هسته برای $P$ می‌گویند اگر رابطه‌ی زیر برقرار باشد:
$$(1 - \epsilon) \mu(P) \leq \mu (Q)$$

\پایان{تعریف}

به عنوان یکی از مجموعه هسته‌های معروف, می‌توان به مجموعه هسته‌ی مطرح برای تابع اندازه‌گیری عرض نقاط اشاره کرد که به آن به اختصار $\epsilon$-هسته\پاورقی{$\epsilon$-Kernel} می‌گوییم.
$\epsilon$-هسته 
یکی از اساسی‌ترین مجموعه هسته‌های مطرح است و برای طیف وسیعی از مسائل قابل استفاده است.
الگوریتم‌های زیادی برای محاسبه‌ی $\epsilon$-هسته در حالت ایستا ارائه شده است \مرجع{agarwal2004approximating}. 

\زیرقسمت{موازی‌سازی}
\مهم{موازی‌سازی} یکی از تکنیک‌های حل مسئله با استفاده از توزیع‌پذیری آن است. به طور معمول از موازی‌سازی برای افزایش سرعت روش یا اطمینان به پاسخ محاسبه‌شده استفاده می‌شود. حال فرض کنید حل‌کننده‌ای \پاورقی{Solver} داریم که اگر پاسخ مورد انتظار (که از ورودی به دست می‌آید) در یک مجموعه‌ی از پیش تعیین‌شده باشد آن را خروجی می‌دهد و در غیر این صورت اعلام می‌کند که پاسخ این مسئله در این مجموعه نیست (و هیچ اطلاعات بیش‌تری راجع خروجی نمی‌دهد). اگر بتوان پاسخ یک مسئله را به مجموعه‌هایی افزار کرد و برای هر مجموعه یک حل‌کننده طراحی کرد، می‌توان با تکنیک موازی‌سازی به پاسخ دقیق مسئله رسید. برای رسیدن به پاسخ دقیق کافی است ورودی مسئله را به حل‌کننده‌ها بدهیم، یکی از حل‌کننده‌ها پاسخ دقیق را دارد و بقیه می‌گویند که پاسخ مسئله در مجموعه‌ی متناظر آن‌ها نیست. حال کافی است پاسخ آن حل‌کننده را به عنوان پاسخ خروجی بدهیم.\\
از این تکنیک حتی در زمانی که پاسخ به مجموعه‌هایی که اشتراکشان ناتهی هست هم می‌توان استفاده کرد. به عنوان مثال فرض کنید ورودی یک مسئله عددی زیر ۱۰۰ است و به دنبال شناسایی اول‌بودن آن عدد هستیم. حال تعدادی حل‌کننده در نظر می‌گیریم که هر کدام بخش‌پذیری عدد بر یک عدد اول (زیر ۱۰۰) را پاسخ می‌دهد. همان‌طور که مشاهده می‌شود مجموعه‌ی متناظر هر حل‌کننده با هم اشتراک دارد (مثلا حل‌کننده‌های ۲و ۳ و ۵ می‌توانند ۳۰ را حل کنند) اما کافی است پاسخ تمام حل‌کننده‌ها را با هم $and$ کنیم که به پاسخ نهایی برسیم.


\قسمت{الگوریتم‌های تقریبی}

در علوم کامپیوتر خانواده‌های زیادی از مسائل وجود دارد. یک مبحث در این مسائل عدم حل‌پذیری برخی از آن‌ها است. شاید معروف‌ترین مثال مسائلی که راه حلی برای آن نداریم مسئله‌ی توقف\پاورقی{Halting problem} باشد. یک برنامه (ماشین تورینگ) و یک ورودی داریم و می‌خواهیم بدانیم آیا این برنامه روی این ورودی متوقف خواهد شد یا خیر. 

این مسائل خیلی در دنیای واقعی کاربرد ندارند. موضوع مهمی که در مسائل حل‌شونده وجود دارد کارآمدی حل آن‌ها است. این کارآمدی می‌تواند به خاطر سرعت پایین الگوریتم یا حجم بالای حافظه باشد. به عنوان مثال اگر الگوریتمی داشته باشیم که زمان مصرفی آن مرتبه‌ی نمایی نسبت به ورودی داشته باشد برای ورودی‌های بزرگ بسیار زمان‌بر خواهد بود و عمل نمی‌توان آن را اجرا کرد.

برای ساده‌کردن بررسی این مسائل گونه‌ای از مسائل به نام تصمیم‌گیری ایجاد شدند.
\شروع{مسئله}
\مهم{(مسائل تصمیم‌گیری)}\پاورقی{Decision problems} به دسته‌ای از مسائل گفته می‌شود که پاسخ آن‌ها تنها بله یا خیر است.
\پایان{مسئله}

به عنوان مثال، نسخه‌ی تصمیم‌گیری مسئله‌ی $k$-مرکز در فضای $|IR^d$ به صورت زیر تعریف می‌شود.

\شروع{مسئله}
\مهم{(نسخه‌ی تصمیم پذیر $k$-مرکز)} مجموعه‌ی نقاط در فضا $\IR^d$ و شعاع $r$ داده شده است، آیا $k$ دایره به شعاع $r$ وجود دارد که تمام نقاط ورودی درون دایره‌ها باشند؟
\پایان{مسئله}
اگر بتوان مسئله‌ی اصلی را به تعدادی مسئله‌ی تصمیم تقسیم کرد می‌توان با حل مسئله‌ی تصمیم مسئله‌ی اصلی را نیز حل کرد.

همان‌طور که احتمالا می‌دانید مهم‌ترین دسته‌بندی مسائل تصمیم‌گیری به خانواده‌ها‌ی مسائل $P$ و $NP$ تقسیم می‌شود. 
مسائلی که راه حل چندجمله‌ای برای حل آن‌ها وجود دارد خانواده‌ی مسائل $P$، به شمار می‌آیند.
مسائلی که در زمان چند‌جمله‌ای می‌توان پاسخ آن‌ها را سنجید خانواده‌ی مسائل $NP$، می‌شوند. به عبارت دیگر اگر پاسخ یک مسئله داده شود آیا می‌توان در زمان چندجمله‌ای مطمئن شد که این پاسخ صحیح است یا خیر.
مسائل مختلفی در علوم کامپیوتر مورد بررسی قرار گرفت که تعدادی از آن‌ها در دسته‌ی $NP$ قرار می‌گیرند اما مطمئن نیستیم که در دسته‌ی $P$ نیز قرار دارند یا خیر.  به این مجموعه مسائل \مهم{$NP$-سخت} می‌گویند. اگر ثابت شود یکی از این مسائل در دسته‌ی $P$ قرار می‌گیرد اثبات می‌شود که $P = NP$.

با توجه به تعریف مسائل $NP$ می‌توان متوجه شد که الگوریتم‌های ارائه‌شده برای آن‌ها کارآمد نیستند.  علاوه بر این برخی از مسائل $P$ نیز دارای الگوریتم کارآمدی نیستند.

بیش‌تر مسائل کاربردی دنیای واقعی جزو خانواده‌ی $NP$-سخت هستند و راه حل چند‌جمله‌ای ندارند. اگر هم این طور نباشد مرتبه‌ی زمانی بالایی دارند. در نتیجه امکان استفاده از این روش‌ها عملی نیست. یک روش برای افزایش سرعت، کاهش دقت پاسخ خروجی است. یعنی به جای این روشی که پاسخ دقیق را در زمان خیلی زیاد به دست می‌آورد، روشی ارائه دهیم تا پاسخ اندکی نادقیق را در زمان بسیار کوتاهی به دست آورد. در صورتی که بتوان برای مقدار خطایی که الگوریتم ایجاد می‌کند کرانی ارائه دهیم به آن یک الگوریتم تقریبی می‌گوییم. الگوریتم تقریبی تضمین می‌کند در هر شرایطی پاسخی خروجی بدهد که از محدوده‌ای بدتر نیست. به عنوان مثال برای مسئله‌ی فروشنده‌ی دوره‌گرد در فضای متریک می‌توان الگوریتمی $2$-تقریب ارائه داد که دوری را خروجی می‌دهد که حداکثر دو برابر کوتاه‌ترین دوری است که از تمام رئوس بگذرد.  به حداکثر نسبت جواب الگوریتم تقریبی به جواب بهینه ضریب تقریب یک الگوریتم تقریبی گفته می‌شود.

\شروع{لوح}[t]
\وسط‌چین
\شروع{جدول}{|c|c|}
\خط‌پر
مسئله & کران پایین تقریب‌پذیری
\\
\خط‌پر
\خط‌پر
$k$-مرکز & $2$\مرجع{vazirani2013approximation} \\ 
$k$-مرکز در فضای اقلیدسی & $1.822$\مرجع{bern1996approximation} \\
$1$-مرکز در حالت جویبار داده & $\frac{1 + \sqrt{2}}{2}$ \مرجع{agarwal2010streaming} \\
$1$-مرکز در مدل پنجره‌ی لغزان (۲-بعدی)& $(1+\epsilon)$\مرجع{chan2006geometric}\\
$2$-مرکز در فضای متریک & $4 + \eps$\مرجع{DBLP:conf/icalp/Cohen-AddadSS16} \\
\خط‌پر
\پایان{جدول}

\شرح{نمونه‌هایی از کران پایین تقریب‌پذیری مسائل بهینه‌سازی}
\برچسب{جدول:تقریب‌پذیری}
\پایان{لوح}

با رویکرد الگوریتم‌های تقریبی به نظر می‌رسد می‌توان برای هر مسئله‌ای تا هر مقدار ضریبی که بخواهیم الگوریتم تقریبی ارائه کرد. در واقعیت چنین چیزی امکان‌پذیر نیست و برای ضریب تقریب مسائل نیز کران پایین وجود دارد. یعنی با فرض $P \neq NP$ بعضی مسائل را در زمان چندجمله‌ای نمی‌توان از حدی دقیق‌تر کرد.

برخی مسائل وجود دارند که حتی نمی‌توان الگوریتم تقریبی با ضریب ثابت برای آن‌ها ارائه کرد. معروف‌ترین مثال این دسته مسئله‌ی فروشنده‌ی دوره‌گرد در حالت کلی است (مسئله‌ی فروشنده‌ی دوره‌گرد در فضای متریک تقریب $2$ دارد).علاوه بر این به طور مثال، همان‌طور که در فصل کارهای پیشین بیان خواهد شد، الگوریتم تقریبی با ضریب تقریب کم‌تر از $2$، برای مسئله‌ی $k$-مرکز وجود ندارد مگر اینکه $P = NP$ باشد.

در جدول \رجوع{جدول:تقریب‌پذیری}  میزان تقریب‌پذیری مسائل مختلفی که در این پایان‌نامه مورد استفاده قرار می‌گیرد (و جزو نتایج این پایان‌نامه نیست) را می‌بینید.

