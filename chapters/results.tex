
\فصل{نتایج جدید}


در این فصل بستری برای حل دسته‌ای از مسائل هندسی در مدل پنجره‌ی لغزان ارائه می‌دهیم. یکی از مهم‌ترین نتایج بستر ارائه‌شده حل مسئله‌ی $k$-مرکز نقاط دوبعدی در مدل پنجره‌ی لغزان با ضریب تقریب $2+\eps$ و با استفاده از حافظه‌ی $\cO(\frac{1}{\eps^2})$ است. بهترین الگوریتم قبلی برای این مسئله دارای ضریب تقریب $6+\eps$ بوده است.

\قسمت{تعاریف اولیه}
در این قسمت برخی مفاهیمی را که برای توضیح الگوریتم‌های این پژوهش به آن نیاز داریم، تعریف می‌کنیم. در این فصل $dis$ تابع اندازه‌ در فضای $d$-بعدی است. به عبارت دیگر داریم:
$$ \forall p, q \in \mathbb{R}^d \Rightarrow dis(p,q) = \sqrt{\sum_{1 \le j \le d} (p_j-q_j)^2}   $$
که $p_j$ مختصات بعد $j$ام نقطه‌ی $p$ است.
\شروع{تعریف}
\مهم{فضای سلولی:}
فضای دکارتی $d$-بعدی را در نظر بگیرید. فرض کنید هر محور آن را به فاصله‌های مساوی به اندازه‌ی $\delta$ تقسیم کرده‌ایم. توری \پاورقی{Grid} حاصل نقاط را به تعدادی \مهم{سلول} افراز می‌کند.  یک سلول مجموعه‌ی شامل نقاط واقع در
$$ [\, i_1 \delta, (i_1+1) \delta ) \times [\, i_2 \delta, (i_2+1) \delta ) \ldots \times [\, i_d \delta, (i_d+1) \delta )  $$
تعریف می‌کنیم و آن را با $(i_1, i_2, \ldots, i_d)$ نشان می‌دهیم. به ازای هر نقطه‌ی دلخواه $p$، سلول $p$ معادل است با مجموعه‌ای که نقطه‌ی $p$ را در بر دارد و به صورت $C_p$ نشان می‌دهیم.
\پایان{تعریف}
\شروع{تعریف}
\مهم{تابع فاصله‌ی سلولی:}
فرض کنید دو سلول $C_u$ و $C_v$ وجود دارند.  در صورتی که کوتاه‌ترین فاصله‌ی گوشه‌های سلول‌های $C_u$ و $C_v$ را برابر $m(C_u, C_v)$ بدانیم فاصله‌ی آن دو سلول به صورت زیر تعریف می‌شود. 
$$ g(C_u, C_v) \equiv m(C_u, C_v) + 2 \sqrt{d} \cdot \delta $$ 
\پایان{تعریف}
در طول فصل برای تعیین عرض سلول‌ها، $\delta$، فضاهای سلولی از دو پارامتر دیگر به نام‌های $\alpha$ و $\eps$ استفاده می‌کنیم (که در آینده به شرح آن‌ها خواهیم رسید). از این پس فرض می‌کنیم هر فضای سلولی با دو پارامتر $\alpha$ و $\eps$ شناسایی می‌شود و داریم:
$$\delta = \frac{\alpha \eps}{2 \sqrt{d}}$$
حال برخی از خواص فضای سلولی را شرح می‌دهیم.
\شروع{لم}
\برچسب{لم:longcelldis}
به ازای دو سلول دلخواه $C_u$ و  $C_v$ و هر دو نقطه‌ی $p$ و $q$ که 
$p \in C_u$  و $q \in C_v$
داریم
$$ g(C_u, C_v) \ge dis(p, q)$$
\شروع{اثبات}
مقدار $\sqrt{d} \cdot \delta $ برابر با بیش‌ترین فاصله‌ی بین گوشه‌های یک سلول است. طبق تعریف، فاصله‌ی سلولی برابر با کم‌ترین فاصله‌ی گوشه‌های دو سلول‌ به اضافه‌ی دو بیش‌ترین فاصله‌ی درون سلول است. در نتیجه به علت اصل نامساوی مثلثی بزرگ‌ترین فاصله‌ی بین گوشه‌های سلول (که از هر $dis(p,q)$ بیش‌تر است) از مقدار $g(C_u, C_v)$ کم‌تر است. در نتیجه لم اثبات می‌شود.
\پایان{اثبات}
\پایان{لم}
یکی از خواص مهم فضای سلولی که در قسمت‌های بعدی از آن استفاده می‌کنیم تقریب فواصل بیش از $\alpha (1 + \eps)$ است. در لم \رجوع{لم:gmeasure} این خاصیت مهم را معرفی و اثبات می‌کنیم.
\شروع{لم}
\برچسب{لم:gmeasure}
به ازای هر دو نقطه‌ی $u$ و $v$ دو ویژگی زیر را داریم:
\شروع{فقرات}
\فقره{ 
اگر 
$ dis(u, v) \le \alpha (1+\eps) $
آن‌گاه 
 $g(C_u, C_v) \le  \alpha (1+\eps)^2 $

}
\فقره{ 
اگر 
$ dis(u, v) > \alpha (1+\eps) $
آن‌گاه 
 $g(C_u, C_v) \le  dis(u, v) (1+\eps) $
}
\پایان{فقرات}

\شروع{اثبات}
برای ویژگی اول می‌دانیم
$ m( C_u, C_v) \le dis(u,v) \le \alpha (1+\eps)$
و در نتیجه
$$ g(C_u, C_v) = m(C_u, C_v) + 2 \sqrt{d} \delta = m(C_u, C_v) + \alpha \eps \le \alpha (1+ 2 \eps) \le \alpha (1 + \eps)^2$$
در حالت دوم طبق لم \رجوع{لم:longcelldis} می‌دانیم
$$ g(C_u, C_v)‌ = m(C_u, C_v) +‌ 2\sqrt{d} \delta = m(C_u, C_v) + \alpha \eps  \ge dis(u, v) > \alpha (1 + \eps)$$
که نتیجه می‌دهد
$ m(C_u, C_v) \ge \alpha $.
و در نتیجه داریم 
$$ g(C_u, C_v) = m(C_u, C_v) + \alpha \eps \le m(C_u, C_v) (1+\eps) \le dis(u, v) (1 + \eps)$$
و به این ترتیب لم اثبات می‌شود.
\پایان{اثبات}
\پایان{لم}

طبق لم \رجوع{لم:gmeasure} اگر فاصله‌ی هر دونقطه‌ای از مقدار مشخصی بیش‌تر باشد ، فاصله‌ی سلولی تقریبی $1+\eps$ از فاصله‌ی آن دو نقطه می‌دهد و اگر کم‌تر باشد فاصله‌ی سلولی کران بالا دارد. این محدودیت را در مشاهده‌ی \رجوع{مشاهده:diacor} بیان کرده‌ایم.
\شروع{مشاهده}
\برچسب{مشاهده:diacor}
در صورتی که قطر $n$ نقطه‌ی دلخواه برابر 
$ r \le \alpha (1+\eps)$
باشد و بزرگ‌ترین فاصله‌ی آن نقاط توسط تابع فاصله‌ی $g$ برابر با $w$ باشد آن‌گاه داریم: 
$ w \le \alpha (1+\eps)^2 $ 
\پایان{مشاهده}
در صورتی که بخواهیم فاصله‌ی بین هر زوج نقطه در یک مجموعه از نقاط را داشته باشیم نیازمند نگه‌داری تمامی آن نقاط هستیم. فضای سلولی به ما این امکان را می‌دهد تا مجموعه‌ای از نقاط را به یک سلول نگاشت دهیم. با این که نمی‌توانیم فاصله‌ی دقیق هر دو نقطه را به وسیله‌ی سلول‌های متناظر آن به دست اوریم اما در عوض می‌توانیم به جای نگه‌داری حجم زیادی از نقاط تنها سلول‌های متناظر آن‌ها را ذخیره کنیم که حافظه‌ی بسیار کم‌تری نیاز دارد. در لم \رجوع{لم:geps} خاصیت مهمی از فضای سلولی را معرفی می‌کنیم که باعث می‌شود حجم سلول‌های مجموعه‌ای از نقاط، مستقل از تعداد خود نقاط باشد.
\شروع{لم}
\برچسب{لم:geps}
اگر بتوان $n$ نقطه‌ را به $C$ (عدد ثابت) دسته‌ افراز کرد که قطر هر دسته 
$ \cO(\alpha (1+\eps)) $
باشد، تعداد سلول‌های متناظر آن نقاط از مرتبه‌ی
$ \cO(\frac{\sqrt{d}}{\eps^d})$ 
خواهد بود.
\شروع{اثبات}
اگر قطر نقاط هر دسته 
$\cO( \alpha (1+ \eps))$
باشد طبق مشاهده‌ی \رجوع{مشاهده:diacor} قطر سلول‌های متناظر این نقاط از 
$\cO( \alpha (1+\eps)^2)$
خواهد بود که با توجه به این که عرض سلول‌ها برابر است با
$ \frac{\alpha \eps}{2 \sqrt{d}}$
در نتیجه تمام نقاط در کره‌ای از سلول‌ها که قطر آن از 
$ \cO(\frac{\sqrt{d}}{\eps})$
سلول تشکیل می‌شود قرار می‌گیرند. چون ابعاد فضا $d$ است، تعداد کل سلول‌های این محدوده از مرتبه‌ی
$ \cO(\frac{\sqrt{d}}{\eps^d})$ 
خواهد بود. با توجه به این که تعداد ثابتی دسته ($C$) داریم در مرتبه‌ی حافظه تغییری ایجاد نمی‌شود و تعداد سلول‌های کل از مرتبه‌ی
$ \cO(\frac{\sqrt{d}}{\eps^d})$ 
خواهد شد.
\پایان{اثبات} 
\پایان{لم}
\شروع{تعریف}
\مهم{مسئله‌ی بهینه‌سازی $C$-پوشا:}
فرض کنید $\pi$ یک مسئله‌ی بهینه‌سازی باشد که ورودی آن $n$ نقطه است. هم‌چنین $\rho$ تابع هدف مسئله‌ی $\pi$ است . مسئله‌ی $\pi$ را $C$-پوشا می‌نامیم اگر دو شرط زیر را داشته باشد.
\شروع{فقرات}
\فقره{
\مهم{یک‌نوایی:} پاسخ هر زیرمجموعه‌ای از تمام نقاط کوچک‌تر مساوی پاسخ تمام نقاط باشد. به عبارت دیگر داشته باشیم
$$ \forall Q \subseteq P : \rho(Q) \le \rho(P) $$
}
\فقره{ به ازای مجموعه‌ی نقاط $P$، می‌توان  $P$ را به $C$ دسته افراز کرد که فطر هر دسته از مرتبه‌ی $\cO(\rho(P))$ باشد.}
\پایان{فقرات}
به عنوان مثال مسئله‌ی محاسبه‌ی قطر نقاط یک مسئله‌ی $1$-پوشا است. همین‌طور $k$-مرکز هندسی یک مسئله‌ی $k$-پوشا است زیرا اگر به ازای پاسخ بهینه، هر مرکز و نقطه‌هایی که به آن مرکز از همه نزدیک‌ترند را در یک دسته قرار دهیم، $k$ دسته خواهیم داشت که قطر هر دسته حداکثر برابر با پاسخ بهینه است.
\پایان{تعریف}

حال مفاهیم مربوط به جویبار داده و پنجره‌ی لغزان که در این فصل استفاده می‌کنیم را معرفی می‌کنیم. همان‌طور که در فصل‌های قبل گفتیم مدل پنجره‌ی لغزان از مدل جویبار داده مشتق شده است که نقاط یکی پس از دیگری وارد می‌شود. هم‌چنین نقاط به ترتیبی که وارد شدند منقضی می‌شوند و در هر لحظه دنباله‌ای از نقاط داریم (پنجره) که می‌خواهیم تابع هدف را برای آن محاسبه کنیم. پس از ورود $j$امین نقطه از جویبار داده (در چرخه‌ی $j$ام)، $P_j$ را برابر دنباله‌ی آخرین $N$ نقطه تا چرخه‌ی $j$ در نظر می‌گیریم. به عبارت دیگر $P_j$ دنباله‌ی نقاط 
$j-N+1$
 تا $j$ام است (اگر $ j < N$ آن‌گاه $P_j$ را تمام نقاط از ابتدا تا $j$ در نظر می‌گیریم). $P_j[k]$ را برابر با $k$مین عضو $P_j$ در نظر می‌گیریم (هر چقدر $k$ کوچک‌تر باشد آن نقطه پیرتر است یا زودتر وارد شده است). به زبان دیگر $P_j$ پنجره‌ی نقاط معتبر پس از چرخه‌ی $j$ است.

\قسمت{چارچوب حل مسائل $C$-پوشا در پنجره‌ی لغزان}
 در این قسمت الگوریتمی برای حل یک مسئله‌ی $C$-پوشا در فضای $d$-بعدی مدل پنجره‌ی لغزان ارائه می‌کنیم. الگوریتم ما دارای ضریب تقریب $(1+\eps)$ است و از حافظه‌ی $\cO(\frac{\sqrt{d}}{\eps^d})$ استفاده می‌کند. برای توضیح الگوریتم ابتدا تعاریف زیر را در نظر می‌گیریم.
 
دنباله‌ی $P$ را برابر با نقاط معتبر داخل پنجره و دنباله‌ی $S$ را برابر دنباله‌‌ای از سلول‌هایی که الگوریتم نگه‌داری می‌کند در نظر می‌گیریم  فرض کنید $\rho(P)$ پاسخ مسئله‌ی $\pi$ برای نقاط $P$ و تابع $\rho_C(S)$ پاسخ مسئله‌ی $\pi$ برای سلول‌های $S$ را محاسبه می‌کند. 
\شروع{تعریف}[نقاط بد] نقطه‌ی $p \in P$ را یک نقطه‌ی بد می‌گوییم اگر پاسخ مسئله‌ی $\pi$ برای نقاط جوان‌تر از $p$ به همراه خود $p$ بیش‌تر از $\alpha (1+\eps)$ باشد. به عبارت دیگر اگر مجموعه‌ی نقاط جوان‌تر از $p$ به همراه خود $p$ را $PB_p$ در نظر بگیریم خواهیم داشت:
$ \rho(B_p) > \alpha (1+\eps)^2$
\پایان{تعریف}
\شروع{تعریف}[سلول بد] به جوان‌ترین سلول در $S$  ($S$)سلول بد می‌گوییم که اگر پاسخ مسئله‌ی $\pi$ برای سلول‌های جوان‌تر از $s$ به همراه خود $s$ بیش‌تر از $\alpha (1+\eps)$ باشد. به عبارت دیگر اگر مجموعه‌ی سلول‌های جوان‌تر از $s$ به همراه خود $s$ را $SB_s$ در نظر بگیریم خواهیم داشت:
$ \rho_C(SB_s) > \alpha (1+\eps)^2$
\پایان{تعریف}
حال سراغ روش پیشنهادی این پژوهش می‌رویم. برای حل مسئله‌ی $\pi$ در مدل پنجره‌ی لغزان از تکنیک موازی‌سازی استفاده می‌کنیم. مسئله‌ی تصمیم $\pi$ را به صورت زیر تعریف می‌کنیم.
\شروع{مسئله}[تصمیم $\pi$]
به ازای پارامترهای ورودی $\alpha$ و $\eps$ می‌خواهیم با توجه به $\rho(P)$ به سوال‌های زیر پاسخ دهیم:
\شروع{فقرات}
\فقره{در صورتی که $\rho(P)$ کوچک‌تر از $\alpha ( 1+ \eps)$ بود پاسخ بله خروجی بده.}
\فقره{در صورتی که $\rho(P)$ بیش‌تر از $\alpha (1+\eps)^2$ بود پاسخ خیر خروجی بده.}
\فقره{در غیر این صورت پاسخ بله یا خیر خروجی بده.}
\پایان{فقرات}
\پایان{مسئله}
به عبارت دیگر این مسئله‌ی تصمیم روی بازه‌ای متمرکز شده است که پاسخ در آن باشد. اهمیت پارامتر‌های $\alpha$ و $\eps$ هم این‌جا مشخص می‌شود. $\alpha$ تخمینی از پاسخ  و $\eps$ معیاری برای بازه‌‌ی خطای این تخمین است. می‌خواهیم حل‌کننده‌ای طراحی کنیم که به مسئله‌ی تصمیم $\pi$ پاسخ دهد.  شرح روش پیشنهادی ما در الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} آمده است.

\شروع{الگوریتم}{تصمیمcپوشا}
\caption
{الگوریتم حل مسئله‌ی تصمیم $\pi$ مدل پنجره‌ی لغزان}
\دستور{$S = \emptyset$ (دنباله‌ی سلول‌های معتبر)}
\دستور{$\alpha , \eps$ = پارامترهای ورودی}
\به‌ازای{هر نقطه‌ی ورودی $p$ از جویبار داده}
\دستور{سلول‌های منقضی‌شده را از $S$ حذف کن}
\دستور{اگر $C_p$ در $S$ بود آن را حذف کن.}
\دستور{$C_p$ را (به همراه زمان ورودش) اضافه کن.}
\اگر{$ \rho_C(S) \le \alpha  (1+\eps)^2$}
\دستور{پاسخ بله را برگردان}
\وگرنه
\دستور{ $w$ را سلول بد در $S$ در نظر بگیر.} \برچسب{الکی}
\دستور{سلول‌های قبل از $w$ را از $S$ حذف کن.}
\دستور{پاسخ خیر را برگردان}
\پایان‌اگر{}
\پایان‌به‌ازای{}
\پایان{الگوریتم}

در گام اول ثابت می‌کنیم مجموعه‌ی سلول‌هایی که الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} در $S$ نگه‌داری می‌کند برای حل مسئله کفایت می‌کند. این موضوع را به وسیله‌ی قضیه‌ی \رجوع{قضیه:spjcoverage} بیان می‌کنیم:
\شروع{قضیه}
\برچسب{قضیه:spjcoverage}
در هر زمان $j$ اگر
$\rho_C(S_j) \le \alpha (1+\eps)^2 $ 
آن‌‌گاه سلول‌های متناظر با تمام نقاط $P_j$ در $S$ وجود دارد و اگر
$\rho_C(S_j) > \alpha (1+\eps)^2 $ 
آن‌گاه سلول‌های متناظر نقاطی از $P_j$ که پیرتر از سلول بد $S_j$ نیستند در $S$ وجود دارد.
\پایان{قضیه}
برای اثبات این قضیه ابتدا چند لم را ثابت می‌کنیم.

\شروع{لم}
\برچسب{لم:jlen1}
در زمان $j \le N$  اگر
$\rho_C(S_j) \le \alpha (1+\eps)^2 $ 
آن‌گاه نماینده‌ی تمام نقاط $P_j$ در $S$ وجود دارد.
\شروع{اثبات}
با توجه به این که در زمان $j$ هیچ نقطه‌ای منقضی نشده است و به خاطر خاصیت یک‌نوایی مسئله‌ی $C-$پوشا، به ازای $ t \le j$ داریم 
$\rho_C(S_t) \le \alpha (1+\eps)^2 $ 
پس تا این زمان هیچ‌گاه به حذف سلول‌های قبل از سلول بد نرسیده‌ایم و اگر سلولی درالگوریتم حذف شده است دوباره همان سلول با زمان ورود جدید به آن اضافه شده است پس به ازای تمام نقاط سلول‌های متناظر آن‌ها نیز موجود است.
\پایان{اثبات}
\پایان{لم}
\شروع{لم}
\برچسب{لم:jlen2}
در زمان $j \le N$ اگر داشته باشیم
$\rho_C(S_j) > \alpha (1+\eps)^2 $
آن‌گاه سلول‌های متناظر نقاطی از $P_j$ که پیرتر از سلول بد $S_j$ نیستند در $S$ وجود دارد.
\شروع{اثبات}
برای اثبات این لم از برهان خلف استفاده می‌کنیم. اولین $t < N$ را در نظر می‌گیریم که شرط لم را نقض می‌کند. سلول بد $S_t$ را $w$ در نظر می‌گیریم. به ازای این $t$ یعنی سلولی ناپیرتر از $w$ وجود دارد که در $S_t$ وجود ندارد. اگر $t$ اولین زمانی است که 
$\rho_C(S_t) > \alpha (1+\eps)^2 $
پس طبق لم \رجوع{لم:jlen1} سلول‌های متناظر تمام نقاط $P_{t-1}$ در $S_{t-1}$ وجود دارد حال با اضافه‌شدن نقطه‌ی جدید تنها سلول‌هایی از $S_t$ حذف شدند که قبل از $w$ یا به قولی پیرتر از آن بوده‌اند. در غیر این صورت این حالت باید در چرخه‌ی قبلی (یعنی زمان $t-1$) هم رخ داده باشد و داریم
$\rho_C(S_{t-1}) > \alpha (1+\eps)^2 $
که طبق فرض سلول‌های متناظر تمام نقاطی از $P_j$ که از سلول‌ بد $S_{t-1}$ پیرتر نیستند، در $S_{t-1}$ وجود دارد. حال با اضافه‌شدن نقطه‌ی جدید، $w$ قطعا ناپیرتر از سلول بد $S_{t-1}$ است. پس تنها سلول‌هایی از $S_t$ حذف می‌شوند که قبل از $w$ یا به قولی پیرتر از آن بوده‌اند. پس چنین $t$ وجود ندارد و لم اثبات می‌شود.
\پایان{اثبات}
\پایان{لم}
\شروع{لم}
\برچسب{لم:jgn1}
در زمان $j > N$  اگر
$\rho_C(S_j) \le \alpha (1+\eps)^2 $ 
آن‌گاه سلول‌های متناظر تمام نقاط $P_j$ در $S$ وجود دارد.
\شروع{اثبات}
برای اثبات این موضوع از استقرا استفاده می‌کنیم. پایه‌‌ی استقرا در زمان $N$ درست است (طبق لم \رجوع{لم:jlen1}). فرض می‌کنیم شرط لم در زمان $j-1$ برقرار بوده است. با ۲ حالت مواجه می‌شویم.
\شروع{فقرات}
\فقره{
حالت اول
$\rho_C(S_{j-1}) \le \alpha (1+\eps)^2 $:
در زمان $j-1$ طبق فرض می‌دانیم که سلول‌های متناظر تمام نقاط $P_{j-1}$ در $S_{j-1}$ موجود است و اگر سلول متناظر اولین نقطه‌ی $P_{j-1}$ در $S_{j-1}$ موجود باشد در $S_j$ حذف می‌شود و پس از ورود نقطه‌ی جدید، در خط $4$ سلول دیگری حذف نمی‌شود. پس سلول‌های متناظر تمام نقاط $P_j$ در $S_j$ موجود است.
}
\فقره{
حالت دوم
$\rho_C(S_{j-1}) > \alpha (1+\eps)^2 $:
در این حالت سلول بد $S_{j-1}$ باید برابر اولین یا پیرترین سلول آن باشد چون در غیر این صورت این نقطه در $S_j$ هم می‌ماند و شرط $\rho_C(S_j) \le B \alpha (1+\eps)^2 $  نقض می‌شود. حال که پیرترین سلول $S_{j-1}$ سلول بد است طبق فرض می‌دانیم که سلول‌های متناظر تمامی نقاط  $P_{j-1}$ که پیرتر از سلول بد در $S_{j-1}$ نیستند در $S_{j-1}$ وجود دارد پس با ورود نقطه‌ی جدید و پس از خط $4$ می‌دانیم سلول‌های متناظر تمام نقاط $P_j$ در $S$ موجود است.
}
\پایان{فقرات}
به این ترتیب حکم استقرا اثبات می‌شود.
\پایان{اثبات}
\پایان{لم}

\شروع{لم}
\برچسب{لم:jgn2}
در زمان $j > N$  اگر
$\rho_C(S) > \alpha (1+\eps)^2 $ 
آن‌گاه سلول‌های متناظر نقاطی از $P_j$ که پیرتر از سلول بد $S_j$ نیستند در $S$ وجود دارد.
\شروع{اثبات}
برای اثبات این موضوع از استقرا استفاده می‌کنیم. پایه برای زمان $N$ درست است (طبق لم \رجوع{لم:jlen2}). فرض می‌کنیم شرط لم در زمان $j-1$ برقرار بوده است. با ۲ حالت مواجه می‌شویم.
\شروع{فقرات}
\فقره{
حالت اول
$\rho_C(S_{j-1}) \le \alpha (1+\eps)^2 $:
در زمان $j-1$ طبق فرض می‌دانیم که سلول‌های متناظر تمام نقاط $P_{j-1}$ در $S_{j-1}$ موجود است و اگر سلول متناظر اولین نقطه‌ی $P_{j-1}$ در $S_{j-1}$ موجود باشد در $S_j$ حذف می‌شود و پس از اضافه‌شدن نقطه‌ی جدید (پس از خط $6$) $S_j$ شامل نمایندگان تمامی نقاط $P_j$ خواهد بود. پس از اجراشدن خط $11$، سلول‌‌های متناظر تمام نقاطی از $P_j$ که از سلول بد $S_j$ پیرتر نیستند، در $S_j$ باقی خواهند ماند.
}
\فقره{
حالت دوم 
$\rho_C(S_{j-1}) > \alpha (1+\eps)^2 $ :
در این حالت سلول بد $S_{j-1}$ یا برابر اولین یا پیرترین ‌سلول آن است که پس از ورود نقطه‌ی جدید و اجرای خط $4$ (حذف این سلول) تمام سلول‌های متناظر $P_j$ در $S$ وجود خواهند داشت یا این طور نیست که پس از ورود نقطه‌ی جدید، سلول بد نمی‌تواند ناپیرتر از سلول بد $S_{j-1}$ باشد و نمایندگان تمامی نقاط ناپیرتر از سلول بد $S_{j-1}$ در $S_j$ وجود دارد. حال پس از اجرای خط $11$ سلول‌های متناظر تمام نقاطی از $P_j$ که از سلول بد $S_j$ پیرتر نیستند، در $S_j$ باقی خواهند ماند. 
}
\پایان{فقرات}
به این ترتیب حکم استقرا اثبات می‌شود.
\پایان{اثبات}
\پایان{لم}

حالت‌های مختلف زمانی و پاسخ الگوریتم را در چندین لم بررسی کردیم. حال می‌توانیم قضیه‌ی \رجوع{قضیه:spjcoverage}  را اثبات کنیم.
\شروع{اثبات}[\مهم{قضیه‌ی \رجوع{قضیه:spjcoverage}}]\\
با استفاده از لم‌های \رجوع{لم:jlen1} و \رجوع{لم:jgn1} حالت اول قضیه‌ی \رجوع{قضیه:spjcoverage} (کفایت سلول‌ها در پاسخ بله) و با استفاده از لم‌های \رجوع{لم:jlen2} و \رجوع{لم:jgn2} حالت دوم قضیه‌ی \رجوع{قضیه:spjcoverage} (کفایت سلول‌ها در پاسخ خیر) اثبات می‌شود. 
\پایان{اثبات}
حال که طبق قضیه‌ی \رجوع{قضیه:spjcoverage} می‌دانیم سلول‌هایی که نگه‌داری می‌شوند برای پاسخ‌گویی به مسئله‌ی تصمیم $\pi$ کافی هستند ثابت می‌کنیم الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} به این مسئله  به درستی پاسخ می‌دهد. بیان این موضوع در قضیه‌ی \رجوع{قضیه:spjcorrectness} آمده است:
\شروع{قضیه}
\برچسب{قضیه:spjcorrectness}
اگر 
$ \rho(P) \le \alpha (1 + \eps) ^ 2 $
‌آن‌گاه داریم
$ \rho_C(S) \le  \alpha (1 + \eps) ^ 2 $
و اگر داشته باشیم
$ \rho(P) > \alpha (1 + \eps) $
آن‌گاه داریم
$ \rho_C(S) > \alpha (1 + \eps) ^ 2 $
\شروع{اثبات}
برای اثبات این قضیه کافی است حالات مختلف $\rho(P)$ را بررسی کنیم.
\شروع{فقرات}
\فقره{اگر 
	$ \rho(P) \le \alpha (1 + \eps) $
	آن‌گاه 
	$ \rho_C(S) \le \alpha (1 + \eps) ^ 2 $.
	
	برای اثبات درستی این حالت فرض خلف می‌کنیم که در چنین حالتی داشته باشیم
	$ \rho_C(S) > \alpha (1 + \eps) ^ 2 $
	آن‌گاه طبق قضیه‌ی \رجوع{قضیه:spjcoverage} تمام نقاطی از $P_j$ که از نقطه‌ی بد $S_j$ پیرتر نیستند در $S$ وجود دارد در نتیجه
	$ \rho(P) > \alpha (1 + \eps) $
	که خلاف فرض اولیه است و این حالت درست است.
}
\فقره{اگر  
	$ \rho(P) > \alpha (1 + \eps)^2 $
	آن‌گاه 
	$ \rho_C(S_j) > B \alpha (1 + \eps) ^ 2 $.\\
	اثبات مشابه حالت اول.
}
\فقره{اگر
	$\alpha (1+\eps) < \rho(P) \le \alpha (1+\eps)^2$
	آن‌گاه 
	$\rho(P) \le \rho_C(S_j) \le  \rho(P) (1+\eps) $\\
		اثبات مشابه حالت اول.
}
\پایان{فقرات}
تمامی حالات بررسی شدند پس قضیه اثبات می‌شود.
\پایان{اثبات}
\پایان{قضیه}

به این ترتیب ثابت می‌شود که الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} در صورتی که قطر نقاط درون پنجره از $\alpha ( 1+\eps)$ کوچک‌تر باشد پاسخ بله می‌دهد و اگر قطر نقاط درون پنجره بزرگ‌تر از $\alpha (1+\eps)^2$ باشد پاسخ خیر می‌دهد. در نتیجه این الگوریتم مسئله‌ی تصمیم $\pi$ را به درستی حل می‌کند.

حال که می‌دانیم روش ما درست کار می‌کند مقدار حافظه‌ی الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} را محاسبه می‌کنیم.
\شروع{قضیه}
\برچسب{قضیه:gmemory}
الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} به مسئله‌ی تصمیم $\pi$ پاسخ درست می‌دهد و حافظه‌ی مصرفی آن از مرتبه‌ی 
$\cO(\frac{\sqrt{d}}{\eps^d})$
است.
 
\شروع{اثبات}
درستی کارکرد الگوریتم در قضیه‌ی \رجوع{قضیه:spjcorrectness} اثبات شد. برای محاسبه‌ی حافظه‌ی مصرفی کافی است اندازه‌ی دنباله‌ی $S$ را به دست آوریم.
در هر چرخه اگر داشته باشیم
$ \rho_C(S) \le \alpha (1 + \eps) ^ 2 $
آن‌گاه طبق خاصیت مسئله‌ی $C-$پوشا می‌توان نقاط را به $C$ دسته تقسیم‌بندی کرد که قطر هر دسته از 
$\cO( \alpha (1 + \eps)^2)$
باشد. طبق ویژگی فضای سلولی (لم 
\رجوع{لم:geps}
)حافظه‌ی مورد نیاز 
$\cO(\frac{\sqrt{d}}{\eps^d})$
است.
و در صورتی که داشته باشیم
$ \rho_C(S) > \alpha (1 + \eps) ^ 2 $ 
طبق الگوریتم می‌دانیم تنها سلول‌های متناظر نقاطی از $P_j$ که پیرتر از سلول بد $S_j$ نیستند در $S$ وجود دارد. اگر سلول‌ بد را $w$ در نظر بگیریم آن‌گاه $S-w$ در مسئله‌ی $C-$پوشا صدق می‌کند و مثل قسمت قبل اندازه‌ی $S$ از 
$\cO(\frac{\sqrt{d}}{\eps^d})$
خواهد بود. با توجه به این که $C$ دسته از این سلول‌ها وجود دارد و $C$ ثابت است اندازه‌ی $S$ و حافظه‌ی مصرفی الگوریتم برابر با
$\cO(\frac{\sqrt{d}}{\eps^d})$
خواهد بود.
\پایان{اثبات}
\پایان{قضیه}

تا به این‌جا یک الگوریتم حل مسئله‌ی تصمیم $\pi$ داشتیم که با ورودی گرفتن $\alpha$ و $\eps$ تشخیص می‌داد پاسخ بزرگ‌تر از $\alpha (1+\eps)^2$ است. برای مسئله‌ی $C$-پوشا در مدل پنجره‌ی لغزان می‌دانیم نسبت بزرگ‌ترین پاسخ $(M)$ به کوچک‌ترین پاسخ $(m)$ در هر پنجره‌ای برابر با $R$ است. پس کافی است بازه‌ی 
$ [\, m, M]\,$
را به زیربازه‌هایی تقسیم کنیم و هر زیربازه را به یک الگوریتم تصمیم اختصاص دهیم. تنها چیزی که در این الگوریتم‌ها متفاوت است ورودی‌های فضای سلولی آن‌ها است که به صورت زیر به آن مقدار می‌دهیم.
$$ \forall i \in  \{1, \ldots, \log_{1+\eps}^{R} \}: \alpha_i = m  (1+\eps)^i$$
یعنی به نمونه‌ی شماره‌ی $i$  الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} ورودی $\alpha_i$ و $\eps$ می‌دهیم. جزییات پیاده‌سازی این الگوریتم را می‌توانید در الگوریتم \رجوع{الگوریتم: حلcپوشا} مشاهده کنید.

\شروع{الگوریتم}{حلcپوشا}
\caption
{الگوریتم محاسبه‌ی پاسخ $\pi$ در مدل پنجره‌ی لغزان}
\به‌ازای{هر $ i \in  \{1, \ldots, \log_{1+\eps}^{R} \}$ }
\دستور{یک نمونه از الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} با پارامتر‌های ورودی $\alpha_i$ و $\eps$ ایجاد کن.}
\پایان‌به‌ازای{}
\به‌ازای{هر نقطه‌ی ورودی $p$ از جویبار داده}
\به‌ازای{هر$ i \in  \{1, \ldots, \log_{1+\eps}^{R} \}$ }
\دستور{نقطه‌ی $p$ را در نمونه‌ی $i$ الگوریتم\رجوع{الگوریتم: تصمیمcپوشا}  درج کن.}
\پایان‌به‌ازای{}
\اگر{ نمونه‌ی $j$ اولین نمونه‌ای بود که پاسخ بله داشت}
\دستور{مقدار $\alpha_j (1+\eps)^2$ را به عنوان خروجی برگردان.}
\پایان‌اگر{}

\پایان‌به‌ازای{}
\پایان{الگوریتم}

حال نتیجه‌ی این الگوریتم را بازنویسی می‌کنیم.
\شروع{قضیه}
الگوریتم  \رجوع{الگوریتم: حلcپوشا} پاسخ مسئله‌ی $\pi$ برای نقاط داخل پنجره را با ضریب تقریب $(1+\eps)$ به دست می‌آورد و حافظه‌ی مصرفی آن از مرتبه‌ی 
$ \log R \frac{\sqrt{d}}{\eps^{d+1}}$
 است.
\شروع{اثبات}
با توجه به این که مقدار پاسخ مسئله‌ی $\pi$ در بازه‌ی $ [\, m, M]\,$ قرار دارد و تمامی این بازه پوشیده شده است، حتما نمونه‌ای از الگوریتم‌های تصمیم وجود دارد که پاسخ بله بدهد.   زیرا اگر آخرین نمونه‌ی الگوریتمی که با $\alpha$ معادل $M$ اجرا می‌شود را در نظر بگیریم، اگر پاسخ مسئله از 
$\alpha (1 +\eps)$
کوچک‌تر باشد بله را خروجی می‌دهد. فرض کنید نمونه‌ی $i$ الگوریتم پاسخ بله را خروجی می‌دهد (مقدار $S$ در نمونه‌ی الگوریتم $i$ را $AS_i$ می‌نامیم). یعنی
$ \rho_C(AS_i) \le \alpha_i (1 + \eps) ^ 2 $
طبق قضیه‌ی \رجوع{قضیه:spjcorrectness} داریم
$ \rho(P) \le \alpha_i (1 + \eps) ^ 2 $
و چون نمونه‌ی $i-1$ الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} پاسخ را پیدا نکرده است پس داریم
$ \rho_C(AS_{i-1}) > \alpha_{i-1} (1+\eps)^2$
طبق قضیه‌ی \رجوع{قضیه:spjcorrectness} داریم
$ \rho(P) >  \alpha_{i-1} (1 + \eps) $.
از این دو مورد می‌توانیم نتیجه‌گیری کنیم
$$   \alpha_{i-1} (1 + \eps) < \rho(P) \le  \alpha_i (1 + \eps) ^ 2  $$
$$ \rightarrow m (1+\eps)^i < \rho(P) \le m (1+\eps)^{i+2} $$
یعنی پاسخی که ما خروجی می‌دهیم حداکثر 
$(1 + \eps)^2$
برابر پاسخ بهینه است. برای این که ضریب تقریب برابر $(1+\eps)$ باشد مقدار $\frac{\eps}{3}$ را به عنوان ورودی الگوریتم می‌دهیم زیرا داریم
$$ (1+\frac{\eps}{3})^2 = 1 + \frac{2}{3} \eps + \frac{\eps^2}{9} \le (1+\eps)$$

هم‌چنین با توجه به این که $\log_{1+\eps}^{R} $ نمونه‌ی الگوریتم داریم و طبق قضیه‌ی \رجوع{قضیه:gmemory} حافظه‌ی مصرفی هر نمونه برابر است با 
$\cO(\frac{\sqrt{d}}{\eps^d})$
  پس حافظه‌ی کل می‌شود 
$ \cO(\log_{1+\eps}^{R} \frac{\sqrt{d}}{\eps^d})$
با توجه به این که می‌دانیم
$ \log_{1+\eps}^{R} \le \frac{\log R}{\eps} $
می‌توانیم مرتبه‌ی حافظه را به صورت
$ \cO(\log R \frac{d}{\eps^{d+1}})$
بازنویسی کنیم.
\پایان{اثبات}
\پایان{قضیه}

 تنها موردی که تا به حال مورد بحث قرار نگرفته است مرتبه‌ی زمانی اجرای الگوریتم است. علت این امر وابستگی مرتبه‌ی زمانی الگوریتم‌ \رجوع{الگوریتم: تصمیمcپوشا} به زمان مصرفی الگوریتم $\rho_C$ است. این مورد را در قسمت بعد که نمونه‌هایی از مسائل $C$-پوشا را حل می‌کنیم بررسی می‌کنیم.
 
 در این قسمت با چارچوب حل مسائل $C$-پوشا آشنا شدیم و الگوریتم \رجوع{الگوریتم: حلcپوشا} را برای حل این مسائل معرفی کردیم. در قسمت بعد با معرفی چندین مسئله‌ی $C$-پوشا آن‌ها را به وسیله‌ی چارچوب معرفی‌شده حل می‌کنیم.  سپس  نتیجه‌ی خودمان را با الگوریتم‌های موجود دیگران از جنبه‌های ضریب تقریب، حافظه‌ی مصرفی و زمان مصرفی مقایسه می‌کنیم.
 
\قسمت{تحلیل تعدادی از مسائل $C$-پوشا}
در قسمت قبل الگوریتم چارچوب حل مسائل $C$-پوشا در مدل پنجره‌ی لغزان را معرفی کردیم. در این فصل می‌خواهیم نمونه‌هایی از مسائل $C$-پوشا را در این چارچوب حل کنیم و با راه حل‌‌هایی که برای آن ارائه شده است مقایسه کنیم. مهم‌ترین نتیجه‌ی این چارچوب حل مسائل $C$-پوشا با استفاده از تمامی الگوریتم‌های شناخته‌شده و جدید بهینه‌سازی هندسی در مدل ایستا است. به عبارت دیگر اگر الگوریتمی سریع برای حل دقیق یک مسئله‌ در مدل ایستا وجود داشته باشد می‌توانیم همان مسئله را در مدل پنجره‌ی لغزان حل کنیم.
\زیرقسمت{قطر}
برای شروع مسئله‌ی محاسبه‌ی قطر را در نظر بگیرید. این مسئله جزو مسائل $1$-پوشا به شمار می‌آید. برای حل این مسئله به وسیله‌ی چارچوبی که ارائه کردیم تنها نیاز به روشی برای محاسبه‌ی قطر به صورت دقیق در مدل ایستا نیاز داریم.
یکی از ساده‌ترین روش‌هایی که برای محاسبه‌ی قطر به ذهن می‌رسد مقایسه‌ی هر دو سلول با یک‌دیگر و پیدا‌کردن بزرگ‌ترین‌ فاصله‌ی بین آن‌ها است.

برای تحلیل این الگوریتم اگر مجموعه‌ی ورودی را $S$ در نظر بگیریم (که در الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} نگه‌داری می‌شود) مرتبه‌ی زمانی این روش معادل با 
$\cO(|S|^2)$
است. پس الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} به ازای هر نقطه‌ی ورودی زمانی از مرتبه‌ی $\cO(|S|^2)$ مصرف می‌کند. با توجه به این که در الگوریتم \رجوع{الگوریتم: حلcپوشا} از 
$\cO(\frac{\log R}{\eps})$
نمونه از الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} اجرا می‌شود (با فرض این که پردازش نمونه‌ها به صورت سری انجام می‌شود) زمان مصرفی کل برابر با مجموع زمان مصرفی هر نمونه از الگوریتم است. مقدار $S$ هم طبق قضیه‌ی \رجوع {قضیه:gmemory} برابر با
$\cO(\frac{\sqrt{d}}{\eps^d})$
	است. پس مرتبه‌ی زمانی هر نمونه برابر با
$\cO(\frac{d}{\eps^{2d}})$
	و هزینه‌ی زمانی کل برابر با
$\cO(\frac{d \log R}{\eps^{2d+1}})$
	می‌شود.
 در نتیجه با این روش می‌توانیم الگوریتمی برای محاسبه‌ی قطر نقاط $d$-بعدی در پنجره‌ی لغزان با ضریب تقریب $1+\eps$، حافظه‌ی مصرفی 
 $\cO(\frac{\sqrt{d} \log R}{\eps^{d+1}})$
  و زمان پردازش ورود هر نقطه از مرتبه‌ی
   $\cO(\frac{d \log R}{\eps^{2d+1}})$
   	 ارائه دهیم.
   	 
برای ابعاد پایین ($2$-بعد و $3$-بعد) الگوریتم‌های سریع‌تری برای محاسبه‌ی قطر وجود دارد. ایده‌ی اصلی این روش‌ها استفاده از پوش محدب است و مرتبه‌ی زمانی آن‌ها معادل با
$\cO(|S| \log |S|)$
است. در صورت استفاده از پوش محدب باید به این نکته دقت کنیم که سلول‌ها باید در فضای اقلیدسی باشند. برای این کار کافی است گوشه‌های هر سلول را به عنوان نمایندگان آن سلول در فضای اقلیدسی در نظر بگیریم و پس از پایان محاسبه، فاصله‌ی دو سلولی که انتخاب شدند را خروجی بدهیم.

زمان مصرفی الگوریتم \رجوع{الگوریتم: تصمیمcپوشا} با استفاده از این روش‌های سریع برابر با
$\cO(\frac{1}{\eps^{d}} \log \frac{1}{\eps^{d}})$
و مرتبه‌ی زمان الگوریتم \رجوع{الگوریتم: حلcپوشا} برابر با
$\cO(\frac{\log R}{\eps^{d+1}} \log \frac{1}{\eps^{d}})$
می‌شود. در نتیجه برای محاسبه‌ی قطر در صفحه، الگوریتمی با ضریب تقریب $1 + \eps$، حافظه‌ی
 $\cO(\frac{\log R}{\eps^{3}})$
 و زمان از مرتبه‌ی 
  $\cO(\frac{\log R}{\eps^{3}} \log \frac{1}{\eps})$
  داریم. هم‌چنین برای محاسبه‌ی قطر در فضای $3$-بعدی الگوریتمی با ضریب تقریب $1 + \eps$، حافظه‌ی
  $\cO(\frac{\log R}{\eps^{4}})$
  و زمان از مرتبه‌ی 
  $\cO(\frac{\log R}{\eps^{4}} \log \frac{1}{\eps})$
خواهیم داشت.
 

\زیرقسمت{کوچک‌ترین کره‌ی محیطی}
مسئله‌ی $MEB$ را در نظر بگیرید که هدف آن پیدا‌کردن کوچک‌ترین کره‌ای است که تمام نقاط ورودی را بپوشاند. این مسئله به وضوح یک مسئله‌ی $1$-پوشا است زیرا اگر تمام نقاط را در یک دسته در نظر بگیریم قطر آن دسته حداکثر دو برابر پاسخ مسئله (شعاع توپ) خواهد بود. پس می‌توانیم از سریع‌ترین الگوریتم محاسبه‌ی $MEB$ در مدل ایستا استفاده کنیم. همان‌طور که در فصل کارهای گذشته دیدیم سریع‌ترین الگوریتم محاسبه‌ی $MEB$ در فضای $d$-بعدی \مرجع{chazelle1996linear} مرتبه‌ی زمانی
 $\cO((d+1)! |S|)$
  دارد. مشابه محاسباتی که در قسمت قطر انجام دادیم زمان اجرای الگوریتم برای یک نمونه  برابر با 
$ \cO((d+1)! \frac{\sqrt{d}}{\eps^d})$
از الگوریتم برابر با پس می‌توانیم مسئله‌ی $MEB$ را در مدل پنجره‌ی لغزان با ضریب تقریب $(1+\eps)$، حافظه‌ی 
$ \cO(\log R \frac{\sqrt{d}}{\eps^{d+1}})$
و زمان اجرای
$ \cO((d+1)! \log R \frac{\sqrt{d}}{\eps^{d+1}})$
به ازای ورود هر نقطه حل کنیم.

بهترین الگوریتم قبل از این روش، استفاده از $\eps$-هسته در دوبعد بود \مرجع{chan2006geometric}. این روش از حافظه‌ی 
$ \cO(\frac{1}{\eps^2} log^3 N \log R polylog(R', N, \frac{1}{\eps})$
استفاده می‌کرد. الگوریتم ما علاوه بر این که در فضاهای بیش از دو بعد هم کار می‌کند بلکه در صفحه هم بهبود داشته است. مقدار حافظه‌ی الگوریتم ما در صفحه برابر است با
$ \cO(\log R \frac{1}{\eps^3})$
که نه وابسته به اندازه‌ی پنجره $N$ است و نه پارامترهای دیگری مثل $R'$ که اندازه‌ی عرض هر نقطه‌ی متوالی در تمامی پنجره‌ها است را دارد.
\زیرقسمت{$2$-مرکز هندسی دوبعدی}

در این قسمت به مسئله‌ی $2$-مرکز می‌پردازیم. مسئله‌ی $2$-مرکز  هندسی مسئله‌ای $2$-پوشا است.  توجه به این نکته ضروری است که اگر $k$-مرکز هندسی نباشد (یا به عبارت دیگر گسسته باشد) ویژگی یکنوایی مسئله‌ی $C$-پوشا ارضا نمی‌شود. به عنوان مثال نقض فرض کنید سه نقطه روی یک خط با فاصله‌ی $L$ از یک‌دیگر قرار دارند. در مسئله‌ی $1$-مرکز هندسی   نقطه‌ی میان آن‌ها را به عنوان مرکز انتخاب می‌کنیم و پاسخ مسئله برابر با $L$ می‌شود.  در ضمن هر زیر‌مجموعه‌ای از این ۳ نقطه را هم انتخاب کنیم پاسخ کوچک‌تر مساوی $L$ خواهد شد. در مسئله‌ی $1$-مرکز گسسته تنها می‌توانیم مراکز را از بین نقاط موجود انتخاب کنیم. پاسخ مسئله به ازای این سه نقطه برابر با $L$ است اما اگر عضو میانی را حذف کنیم پاسخ مسئله برابر با $2L$ می‌شود که ویژگی یک‌نوایی را نقض می‌کند. 

در این قسمت به بررسی سریع‌ترین الگوریتم این مسئله در صفحه و در مدل ایستا می‌پردازیم. این الگوریتم مرتبه‌ی زمانی 
$ \cO(|S| log^2 |S| log ^2 log |S|)$
را دارد. پس می‌توانیم مسئله‌ی $2$-مرکز دوبعدی را با ضریب تقریب $1+\eps$، حافظه‌ی 
$ \cO(\log R \frac{1}{\eps^{3}})$
و زمان اجرای
$ \cO(\log R \frac{1}{\eps^3} poylog(\frac{1}{\eps}))$
به ازای ورود هر نقطه حل کنیم.

بهترین روش قبل از ما، دارای ضریب تقریب $4+\eps$ است \مرجع{DBLP:conf/icalp/Cohen-AddadSS16} که روش ما پیشرفت قابل توجهی به وجود آورده است.

\قسمت{حل $(2+\eps)$-تقریب مسئله‌ی $k$-مرکز با ابعاد ثابت}
در قسمت‌های قبل مسائل $C$-پوشا مورد بررسی قرار گرفتند که یک الگوریتم سریع (نزدیک به خطی) و دقیق برای حل مدل ایستای آن‌ها داشته باشیم. مسئله‌ی $k$-مرکز دو خاصیت دارد که با شرایطی که فراهم کردیم سازگار نیست. خاصیت اول این است که $k$-مرکز یک مسئله‌‌ی $NP$-سخت است و نه تنها الگوریتم سریعی برای حل آن وجود ندارد بلکه راه حل چندجمله‌ای نیز برای آن نیست. پس مجبور به استفاده از الگوریتم‌های تقریبی هستیم. از طرف دیگر مسئله‌ی $k$-مرکز گسسته (که مراکز از نقاطی انتخاب شوند که جزو نقاط ورودی باشد) یک مسئله‌ی $C$-پوشا نیست زیرا خاصیت یک‌نوایی این مسئله (پاسخ هر زیرمجموعه‌ای کوچک‌تر مساوی کل نقاط باشد) را ندارد. این موضوع در قسمت $2$-مرکز هندسی  بیش‌تر بررسی شد. پس با این مسئله نمی‌توان مانند مسائل قبلی  $C$-پوشا برخورد کرد. به همین دلیل روش خود را در پاسخ‌دهی به مسئله‌ی تصمیم اندکی تغییر می‌دهیم.

فرض می‌کنیم $\rho(P)$ تابع هدف مسئله‌ی $k$-مرکز برای نقاط $P$ است و $G(S)$ یک روش تقریبی برای حل این مسئله در مدل ایستا با ضریب تقریب $\beta$ است. به دنبال این هستیم که مثل مسائل $C$-پوشا حل‌کننده‌هایی ایجاد کنیم که برای یک بازه درست کار می‌کنند. سپس به صورت موازی از این حل‌کننده‌ها استفاده کنیم و مسئله‌ی $k$-مرکز را حل کنیم. ابتدا به تعریف مسئله‌ی $k$-مرکز می‌پردازیم.

\شروع{مسئله}[تصمیم $k$-مرکز]
به ازای پارامترهای ورودی $\alpha$ و $\eps$ می‌خواهیم با توجه به $\rho(P)$ به سوال‌های زیر پاسخ دهیم:
\شروع{فقرات}
\فقره{در صورتی که $\rho(P)$ کوچک‌تر از $ \alpha ( 1+ \eps)^2$ بود پاسخ بله خروجی بده.}
\فقره{در صورتی که $\rho(P)$ بیش‌تر از $\beta \alpha (1+\eps)$ بود پاسخ خیر خروجی بده.}
\فقره{در غیر این صورت پاسخ بله یا خیر خروجی بده.}
\پایان{فقرات}
\پایان{مسئله}

روش پیشنهادی خود برای پاسخ‌گویی به این سوال را در الگوریتم \رجوع{الگوریتم: تصمیمkمرکز}  شرح داده‌ایم. این الگوریتم مقدار $\alpha$ و $\eps$ را ورودی می‌گیرد و به مسئله‌ی تصمیم $k$-مرکز را پاسخ می‌دهد.
\شروع{الگوریتم}{تصمیمkمرکز}
\caption
{الگوریتم تصمیم‌گیرنده‌ی مسئله‌ی  $k$-مرکز در مدل پنجره‌ی لغزان برای پاسخ کوچک‌تر از $\beta \alpha ( 1+ \eps^2)$ }
\دستور{$S = \emptyset$ (دنباله‌ی سلول‌های معتبر)}
\دستور{$\alpha , \eps$ = پارامترهای ورودی}
\به‌ازای{هر نقطه‌ی ورودی $p$ از جویبار داده}
\دستور{سلول‌های منقضی‌شده را از $S$ حذف کن}
\دستور{اگر $C_p$ در $S$ بود آن را حذف کن.}
\دستور{$C_p$ را (به همراه زمان ورودش) اضافه کن.}
\اگر{حداقل $k+1$ سلول در $S$ وجود نداشت که فاصله‌ی هر کدام از دیگری حداقل $2\beta \alpha(1 + \eps)^2$ بود}
\اگر{$ G(S) \le \beta \alpha  (1+\eps)^2$}
\دستور{پاسخ بله را برگردان}
\وگرنه
\دستور{پاسخ خیر را برگردان}
\پایان‌اگر{}
\وگرنه
\دستور{  جوان‌ترین $k+1$ سلول که از یک‌دیگر حداقل فاصله‌ی $2\beta \alpha (1 + \eps)^2$ دارند را به دست بیاور و پیرترین آن‌ها را $w$ در نظر بگیر }
\دستور{سلول‌های قبل از $w$ را از $S$ حذف کن.}
\دستور{پاسخ خیر را برگردان}
\پایان‌اگر{}
\پایان‌به‌ازای{}
\پایان{الگوریتم}


 برای اثبات درستی الگوریتم ابتدا ثابت می‌کنیم که سلول‌های متناظر تمام نمایندگان در زمانی که پاسخ وجود دارد در $S$ نگه‌داری می‌شود. سپس اثبات می‌کنیم پاسخ این الگوریتم به مسئله‌ی تصمیم $k$-مرکز صحیح است.
 \شروع{لم}
 \برچسب{لم:k1yes}
فرض کنید $k+1$ سلول در $S$ وجود داشته باشند که از یک‌دیگر حداقل فاصله‌ی $2\beta \alpha (1 + \eps)^2$ دارند. تا زمانی که پیرترین این $k+1$ سلول منقضی نشود پاسخ سوال تصمیم $k$-مرکز در این پنجره خیر خواهد بود.
\شروع{اثبات}
برای هر کدام از این $k+1$ سلول، دایره‌ای به شعاع $2\beta \alpha (1 + \eps)^2$ در نظر بگیرید. این دوایر هیچ اشتراکی با هم ندارند. طبق اصل لانه کبوتری هر $k$ نقطه‌ای را انتخاب کنیم قطعا یک دایره پوشش داده نخواهد شد در نتیجه پاسخ $G(S)$ قطعا بیش‌تر از $\beta \alpha (1+\eps)^2$ می‌شود. اگر پاسخ $k$-مرکز توسط الگوریتم تقریبی $G(S)$ بیش‌تر از $\beta \alpha (1+\eps)^2$ بشود یعنی پاسخ $\rho(P)$ بیش‌تر از $\alpha (1+\eps)^2$ بوده است (زیرا $G(S)$ ضریب تقریب $\beta$ دارد و حداکثر $\beta$ برابر پاسخ صحیح را خروجی می‌دهد).
\پایان{اثبات}
 \پایان{لم}
 \شروع{مشاهده}
فرض کنید $k+1$ سلول در $S$ وجود داشته باشند که از یک‌دیگر حداقل فاصله‌ی $2\beta \alpha (1 + \eps)^2$ دارند. پس از منقضی‌شدن پیرترین این $k+1$ سلول، سلول متناظر تمامی نقاط $P$ در $S$ وجود دارد.
 \پایان{مشاهده}
 \شروع{قضیه}
 \برچسب{قضیه: kcorrect}
 الگوریتم \رجوع{الگوریتم: تصمیمkمرکز} در صورتی که پاسخ 
 $\rho(P) > ‌\beta \alpha (1 + \eps)^2$ 
 باشد خروجی خیر می‌دهد و اگر 
  $\rho(P) \le \alpha (1 + \eps)$ 
  پاسخ بله می‌دهد.
  \شروع{اثبات}
  اگر حداقل $k+1$ سلول در $S$ وجود داشته باشد که فاصله‌ی هر کدام از دیگری حداقل $2\beta \alpha(1 + \eps)^2$ باشد طبق لم \رجوع{لم:k1yes} خواهیم داشت  $\rho(P) > \alpha (1 + \eps)^2$. پس از این که پیرترین این نقاط منقضی شدند دیگر تمامی سلول‌های متناظر نقاط $P$ در $S$ وجود دارد و اگر داشته باشیم
    $\rho(P) \le \alpha (1 + \eps)$ 
    آن‌گاه داریم
   $ G(S) \le \beta \alpha  (1+\eps)^2$
   و پاسخ بله خواهیم داد.
  \پایان{اثبات}
 \پایان{قضیه}
 \برچسب{قضیه: kmemory}
 
در پایان مقدار حافظه‌ای که ذخیره می‌شود را به همراه جمع‌بندی الگوریتم \رجوع{الگوریتم: تصمیمkمرکز} به دست می‌آوریم.
\شروع{قضیه}
 الگوریتم \رجوع{الگوریتم: تصمیمkمرکز} مسئله‌ی تصمیم $k$-مرکز را به درستی پاسخ می‌دهد. هم‌چنین حافظه‌ی استفاده‌شده از مرتبه‌ی 
$\cO(\frac{\sqrt{d} \cdot k \cdot \beta}{\eps^d})$
\شروع{اثبات}
درستی الگوریتم طبق قضیه‌ی \رجوع{قضیه: kcorrect} اثبات شد. برای محاسبه‌ی حافظه‌ی مصرفی کافی است اندازه‌ی دنباله‌ی $S$ را به دست آوریم.

در صورتی که حداقل $k+1$ سلول در $S$ وجود نداشت که فاصله‌ی هر کدام از دیگری حداقل $2\beta \alpha(1 + \eps)^2$ باشد پس می‌توان سلول‌ها را به حداکثر $k$ دسته افراز کرد که قطر هرکدام حداکثر $4\beta \alpha(1 + \eps)^2$ باشد. چون داریم $\delta = \frac{\alpha \eps}{2 \sqrt{d}}$ پس قطر هر دسته از مرتبه‌ی
 $\cO(\frac{\sqrt{d}}{\eps})$
 و تعداد سلول‌های داخل دسته از مرتبه‌ی
$\cO(\frac{\sqrt{d} \beta}{\eps^d})$
خواهد بود. در غیر این صورت سلول‌های قبل از پیرترین این $k+1$ سلول را حذف کرده‌ایم در نتیجه باز هم می‌توان به $k+1$ دسته افراز کرد که هر دسته 
$\cO(\frac{\sqrt{d} \beta}{\eps^d})$
سلول را در بر بگیرد. در هر دو حالت حداکثر $k+1$ دسته داشتیم پس حافظه‌ی مصرفی در کل می‌شود
$\cO(\frac{\sqrt{d} \cdot k \cdot \beta}{\eps^2})$
\پایان{اثبات}
\پایان{قضیه}

حال که یک روش برای حل مسئله‌ی تصمیم $k$-مرکز داریم، همانند ایده‌ی موازی‌سازی مسائل $C$-پوشا، بازه‌ی پاسخ را به زیربازه‌هایی تقسیم می‌کنیم و برای هر زیربازه یک نمونه از الگوریتم \رجوع{الگوریتم: تصمیمkمرکز} را اجرا می‌کنیم.

از این به بعد باقی الگوریتم مانند قسمت‌های قبل است (الگوریتم \رجوع{الگوریتم: حلcپوشا})، زیرا یک الگوریتم برای پاسخ‌دهی به مسئله‌ی تصمیم داریم و کافی است بازه‌ی پاسخ را به زیربازه‌هایی تقسیم کنیم و به ازای هر کدام یک نمونه‌ی از الگوریتم تصمیم اجرا کنیم.

برای مسئله‌ی $k$-مرکز در مدل پنجره‌ی لغزان می‌دانیم نسبت بزرگ‌ترین پاسخ $(M)$ به کوچک‌ترین پاسخ $(m)$ در هر پنجره‌ای برابر با $R$ است. پس کافی است بازه‌ی 
$ [\, m, M]\,$
را به زیربازه‌هایی تقسیم کنیم و هر زیربازه را به یک الگوریتم تصمیم اختصاص دهیم. تنها چیزی که در این الگوریتم‌ها متفاوت است ورودی‌های فضای سلولی آن‌ها است که به صورت زیر به آن مقدار می‌دهیم.
$$ \forall i \in  \{1, \ldots, \log_{1+\eps}^{R} \}: \alpha_i = m  (1+\eps)^i$$
یعنی به نمونه‌ی شماره‌ی $i$  الگوریتم \رجوع{الگوریتم: تصمیمkمرکز} ورودی $\alpha_i$ و $\eps$ می‌دهیم. جزییات پیاده‌سازی این الگوریتم را می‌توانید در الگوریتم \رجوع{الگوریتم: حلkمرکز} مشاهده کنید.

\شروع{الگوریتم}{حلkمرکز}
\caption
{الگوریتم محاسبه‌ی پاسخ $k$-مرکز در مدل پنجره‌ی لغزان}
\به‌ازای{هر $ i \in  \{1, \ldots, \log_{1+\eps}^{R} \}$ }
\دستور{یک نمونه از الگوریتم \رجوع{الگوریتم: تصمیمkمرکز} با پارامتر‌های ورودی $\alpha_i$ و $\eps$ ایجاد کن.}
\پایان‌به‌ازای{}
\به‌ازای{هر نقطه‌ی ورودی $p$ از جویبار داده}
\به‌ازای{هر$ i \in  \{1, \ldots, \log_{1+\eps}^{R} \}$ }
\دستور{نقطه‌ی $p$ را در نمونه‌ی $i$ الگوریتم\رجوع{الگوریتم: تصمیمkمرکز}  درج کن.}
\پایان‌به‌ازای{}
\اگر{ نمونه‌ی $j$ اولین نمونه‌ای بود که پاسخ بله داشت}
\دستور{مقدار $\beta \alpha_j (1+\eps)^2$ را به عنوان خروجی برگردان.}
\پایان‌اگر{}

\پایان‌به‌ازای{}
\پایان{الگوریتم}

حال ثابت می‌کنیم الگوریتم \رجوع{الگوریتم: حلkمرکز} مسئله‌ی $k$-مرکز را با ضریب تقریب $ \beta + \eps$ حل می‌کند.
\شروع{قضیه}
الگوریتم  \رجوع{الگوریتم: حلkمرکز} پاسخ مسئله‌ی $k$-مرکز برای نقاط داخل پنجره را با ضریب تقریب $(\beta+\eps)$ به دست می‌آورد و حافظه‌ی مصرفی آن از مرتبه‌ی 
$ k \log R \frac{\sqrt{d}}{\eps^{d+1}}$
است.
\شروع{اثبات}
با توجه به این که مقدار پاسخ مسئله‌ی $k$-مرکز در بازه‌ی $ [\, m, M]\,$ قرار دارد و تمامی این بازه پوشیده شده است، حتما نمونه‌ای از الگوریتم‌های تصمیم وجود دارد که پاسخ بله بدهد. زیرا اگر آخرین نمونه‌ی الگوریتمی که با $\alpha$ معادل $M$ اجرا می‌شود را در نظر بگیریم اگر پاسخ مسئله از 
$\alpha (1 +\eps)$
کوچک‌تر باشد بله را خروجی می‌دهد. فرض کنید نمونه‌ی $i$ الگوریتم پاسخ بله را خروجی می‌دهد (مقدار $S$ در نمونه‌ی الگوریتم $i$ را $AS_i$ می‌نامیم). یعنی
$ G(AS_i) \le \beta \alpha_i (1 + \eps) ^ 2 $
طبق قضیه‌ی \رجوع{قضیه: kcorrect} داریم
$ \rho(P) \le \beta \alpha_i (1 + \eps) ^ 2 $
و چون نمونه‌ی $i-1$ الگوریتم \رجوع{الگوریتم: تصمیمkپوشا} پاسخ را پیدا نکرده است پس داریم
$ G(AS_{i-1}) > \alpha_{i-1} (1+\eps)^2$
طبق قضیه‌ی \رجوع{قضیه: kcorrect} داریم
$ \rho(P) >  \alpha_{i-1} (1 + \eps) $.
از این دو مورد می‌توانیم نتیجه‌گیری کنیم
$$   \alpha_{i-1} (1 + \eps) < \rho(P) \le  \beta \alpha_i (1 + \eps) ^ 2  $$
$$ \Rightarrow m (1+\eps)^i < \rho(P) \le m (1+\eps)^{i+2} $$
یعنی پاسخی که ما خروجی می‌دهیم حداکثر 
$\beta (1 + \eps)^2$
برابر پاسخ بهینه است. برای این که ضریب تقریب برابر $(1+\eps)$ باشد مقدار $\frac{\eps}{3}$ را به عنوان ورودی الگوریتم می‌دهیم زیرا داریم
$$ (1+\frac{\eps}{3})^2 = 1 + \frac{2}{3} \eps + \frac{\eps^2}{9} \le (1+\eps)$$

هم‌چنین با توجه به این که $\log_{1+\eps}^{R} $ نمونه‌ی الگوریتم داریم و طبق قضیه‌ی \رجوع{قضیه: kmemory} حافظه‌ی مصرفی هر نمونه برابر است با 
$\cO(\frac{\sqrt{d}}{\eps^d})$
پس حافظه‌ی کل
$ \cO(k \log R \frac{d}{\eps^{d+1}})$
می‌شود.
\پایان{اثبات}
\پایان{قضیه}

تنها نکته‌ای که برای تکمیل حل $k$-مرکز باقی می‌ماند، حل تابع $G(S)$ است. الگوریتم گنزالز می‌تواند به جای $G(S)$ استفاده شود. این الگوریتم ضریب تقریب $2$ را دارد و در مرتبه‌ی زمانی $\cO(|S| k)$ اجرا می‌شود. به این ترتیب برای مسئله‌ی $k$-مرکز یک الگوریتم با ضریب تقریب $2+\eps$، حافظه‌ی
$ \cO(k \log R \frac{d}{\eps^{d+1}})$
و زمان اجرای
$ \cO(k^2 \log R \frac{d}{\eps^{d+1}})$
برای ورود هر نقطه خواهیم داشت.

بهترین روش در گذشته ضریب تقریب $6+\eps$ داشت \مرجع{DBLP:conf/icalp/Cohen-AddadSS16} که این کاهش ضریب تقریب گام بزرگی در حل دقیق‌تر مسئله به حساب می‌آید.

لازم به ذکر است که الگوریتم‌های محاسبه‌ی قطر و $k$-مرکز به عنوان نمونه شبیه‌سازی شده‌اند و کد آن‌ها در 
\href{https://github.com/noidsirius/SlidingWindowSandBox}{https://github.com/noidsirius/SlidingWindowSandBox}
قابل دسترس است.